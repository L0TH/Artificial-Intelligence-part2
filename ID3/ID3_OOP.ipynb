{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ID3 OOP.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9mZqB_O6ttKP",
        "outputId": "c6f932c1-deb3-44ce-ca8f-df2227a606a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n",
            "17473536/17464789 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n",
            "1654784/1641221 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.imdb.load_data(num_words=4000)\n",
        "\n",
        "word_index = tf.keras.datasets.imdb.get_word_index()\n",
        "index2word = dict((i + 3, word) for (word, i) in word_index.items())\n",
        "index2word[0] = '[pad]'\n",
        "index2word[1] = '[bos]'\n",
        "index2word[2] = '[oov]'\n",
        "x_train = np.array([' '.join([index2word[idx] for idx in text]) for text in x_train])\n",
        "x_test = np.array([' '.join([index2word[idx] for idx in text]) for text in x_test])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary = list()\n",
        "for text in x_train:\n",
        "  tokens = text.split()\n",
        "  vocabulary.extend(tokens)\n",
        "\n",
        "vocabulary = set(vocabulary)\n",
        "print(len(vocabulary))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDCuINfIt-HV",
        "outputId": "4508b5a7-a33d-47de-fa07-4b86b2e5e1e3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3998\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "x_train_binary = list()\n",
        "x_test_binary = list()\n",
        "\n",
        "for text in tqdm(x_train):\n",
        "  tokens = text.split()\n",
        "  binary_vector = list()\n",
        "  for vocab_token in vocabulary:\n",
        "    if vocab_token in tokens:\n",
        "      binary_vector.append(1)\n",
        "    else:\n",
        "      binary_vector.append(0)\n",
        "  x_train_binary.append(binary_vector)\n",
        "\n",
        "x_train_binary = np.array(x_train_binary)\n",
        "\n",
        "for text in tqdm(x_test):\n",
        "  tokens = text.split()\n",
        "  binary_vector = list()\n",
        "  for vocab_token in vocabulary:\n",
        "    if vocab_token in tokens:\n",
        "      binary_vector.append(1)\n",
        "    else:\n",
        "      binary_vector.append(0)\n",
        "  x_test_binary.append(binary_vector)\n",
        "\n",
        "x_test_binary = np.array(x_test_binary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWsHHuq7uAjP",
        "outputId": "be16e501-8b29-4d5a-d8d9-bcbe215c5e3f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 25000/25000 [07:38<00:00, 54.56it/s]\n",
            "100%|██████████| 25000/25000 [07:30<00:00, 55.48it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Word:\n",
        "\n",
        "  def __init__(self, value:str, index:int):\n",
        "    self.value = value\n",
        "    self.index = index\n",
        "    self.ig = None\n",
        "    self.entropy0 = None\n",
        "    self.entropy1 = None\n",
        "  \n",
        "  def setIg(self, ig):\n",
        "    if(ig != None):\n",
        "      self.ig = float(ig)\n",
        "      \n",
        "  def getIg(self):\n",
        "    return self.ig\n",
        "\n",
        "  def setEntropy0(self, entropy0):\n",
        "    self.entropy0 = entropy0\n",
        "\n",
        "  def setEntropy1(self, entropy1):\n",
        "    self.entropy1  = entropy1\n",
        "\n",
        "  def __str__(self):\n",
        "    return self.value\n",
        "\n",
        "  def __repr__(self):\n",
        "    return self.value + \" \" + str(self.ig)\n",
        "  "
      ],
      "metadata": {
        "id": "mcST9vmVuXqO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Node:\n",
        "  value: Word\n",
        "  left = None # must be Node\n",
        "  right = None # must be Node\n",
        "  depth = None\n",
        "  p0 = None\n",
        "  p1 = None\n",
        "\n",
        "  def __init__(self, v: int = None, depth = None):\n",
        "    self.value = v\n",
        "    if depth == None:\n",
        "      self.depth = 10\n",
        "    else:\n",
        "      self.depth = depth\n",
        "  \n",
        "  def setLeftChild(self, v: Word):\n",
        "    self.left = v\n",
        "\n",
        "  def setRightChild(self, v: Word):\n",
        "    self.right  = v\n",
        "\n",
        "  def setChilds(self, l, r):\n",
        "    self.setLeftChild(l)\n",
        "    self.setRightChild(r)\n",
        "\n",
        "  def setP0(self, p0):\n",
        "    self.p0 = p0\n",
        "  \n",
        "  def setP1(self, p1):\n",
        "    self.p1 = p1\n",
        "\n",
        "  def __str__(self):\n",
        "    return self.value.value"
      ],
      "metadata": {
        "id": "gWMya5ftug_Z"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_entropy_word(binary_array, result_array, c, word, word_position, cProb):\n",
        "  if(cProb == 1 or cProb == 0):\n",
        "    return 0\n",
        "  return - ( cProb * np.log2(cProb) ) - ( (1.0 - cProb) * np.log2(1.0 - cProb))\n",
        "\n",
        "\n",
        "def calculate_entropy_total(binary_array, result_array):\n",
        "  first = 0\n",
        "  count = 0\n",
        "  for element in binary_array:\n",
        "      if(result_array[count] == 1):\n",
        "        first += 1\n",
        "      count += 1\n",
        "  cProb = first/binary_array.shape[0]\n",
        "  if(cProb == 1 or cProb == 0):\n",
        "    return 0      \n",
        "  return - ( cProb * np.log2(cProb) ) - ( (1.0 - cProb) * np.log2(1.0 - cProb))"
      ],
      "metadata": {
        "id": "frp3aX1wx4M_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -1 = has not found the word\n",
        "def return_word(word):\n",
        "  count = 0\n",
        "  for element in vocabulary:\n",
        "    if word == element:\n",
        "      return count\n",
        "    else:\n",
        "      count += 1\n",
        "  \n",
        "  return -1"
      ],
      "metadata": {
        "id": "XqKs2Z45yBpf"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_probability(array, result_array, c, word, word_position = -1):\n",
        "  #Entropy\n",
        "  has_the_word = 0 # c value\n",
        "  count = 0 # lengeth\n",
        "  is_positive = 0\n",
        "  if word_position == -1:\n",
        "    word_position = return_word(word) # the word column\n",
        "  \n",
        "  for element in array:\n",
        "      element_i = element[word_position]\n",
        "      count += 1\n",
        "      if(element_i == c):\n",
        "        has_the_word += 1\n",
        "        if(result_array[count-1] == 1):\n",
        "          is_positive += 1\n",
        "  \n",
        "  if(has_the_word == 0):\n",
        "    return 0\n",
        "  \n",
        "  return is_positive/has_the_word"
      ],
      "metadata": {
        "id": "FZcOODQzyDKx"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_probability_total(result_array):\n",
        "  #Node \n",
        "  count = 0\n",
        "  p = 0\n",
        "  for x in result_array:\n",
        "    if(x == 1):\n",
        "      p += 1\n",
        "    count += 1\n",
        "  return p/count"
      ],
      "metadata": {
        "id": "A_y_Ag7AyEQc"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_IG(binary_array, result_array, word, calculate_entrupy_total):\n",
        "    word.setIg(calculate_entrupy_total - calculate_sum(binary_array, result_array, word))"
      ],
      "metadata": {
        "id": "lxA4nB1tyHgM"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def hasTheWord(word1: Word, word2: Word, array):\n",
        "  index1 = int(word1.index)\n",
        "  index2 = int(word2.index)\n",
        "  for x in array:\n",
        "    if(x[index1] == 1 and x[index2] == 1):\n",
        "      return 1\n",
        "  return 0"
      ],
      "metadata": {
        "id": "VIsUfUP7yJrF"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_words(array, word_index, keep_the_word = True):\n",
        "  num = []\n",
        "  c = 1\n",
        "  if(keep_the_word):\n",
        "    c = 0\n",
        "  count = 0\n",
        "  for x in array:\n",
        "    if(x[word_index] == c):\n",
        "      num.append(count)\n",
        "    count+=1\n",
        "\n",
        "  return num"
      ],
      "metadata": {
        "id": "g6wq5ureyLU_"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def findValueFromArray(array, index):\n",
        "  if len(array) < index:\n",
        "    return None\n",
        "  try:\n",
        "    if(array[index] == 1):\n",
        "     return index\n",
        "  except:\n",
        "    return None\n",
        "  return None"
      ],
      "metadata": {
        "id": "l_4sq3xPyOlQ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math \n",
        "def get_my_key(obj:Word):\n",
        "  return obj.getIg()\n",
        "\n",
        "def next_word_subtree(array, result_array, words):\n",
        "  i = 0\n",
        "  et = calculate_entropy_total(array, result_array)\n",
        "  words_to_remove = list()\n",
        "  for word in words:\n",
        "   word.setEntropy0(None)\n",
        "   word.setEntropy1(None)\n",
        "   word.setIg(None)\n",
        "   calculate_IG(array, result_array, word, et)\n",
        "  for x in words:\n",
        "    if x.ig == None or math.isnan(x.ig):\n",
        "     words_to_remove.append(x)\n",
        "  for x in words_to_remove:\n",
        "      words.remove(x)\n",
        "  words = sorted(words, key=get_my_key, reverse=True)\n",
        "  re = words.pop()\n",
        "  return (re, words)\n",
        "\n"
      ],
      "metadata": {
        "id": "QLkHD0zEyP28"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_words():\n",
        "  words = list()\n",
        "  i = 0\n",
        "  for x in vocabulary:\n",
        "    if(x != '[pad]' and x!= '[bos]' and x != '[oov]'):\n",
        "      words.append(Word(x, i))\n",
        "    i+= 1\n",
        "\n",
        "  return words"
      ],
      "metadata": {
        "id": "ADCno_5ZySqQ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_sum(binary_array, result_array, word):\n",
        "    word_position = word.index\n",
        "    p0 = (calculate_probability(binary_array, result_array, 0, word, word_position))\n",
        "    p1 = 1 - p0\n",
        "    word.setEntropy0(calculate_entropy_word(binary_array, result_array, 0, word,  word_position, p0))\n",
        "    word.setEntropy1(calculate_entropy_word(binary_array, result_array, 1, word,  word_position, p1))\n",
        "    if p0 == 0 or word.entropy0 ==0:\n",
        "      a = 0\n",
        "    else:\n",
        "      a = np.log2(p0 * word.entropy0)\n",
        "\n",
        "    if p1 == 0 or word.entropy1 ==0:\n",
        "      b = 0\n",
        "    else:\n",
        "      b = np.log2(p1 * word.entropy1)\n",
        "    return  a + b"
      ],
      "metadata": {
        "id": "JoBqI7RRyFXT"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ID3:\n",
        "  def __init__(self, depth):\n",
        "    self.tree = None\n",
        "    self.depth = depth\n",
        "\n",
        "  def anadromi(self, array, result_array, depth, words = None):\n",
        "    if(words == None):\n",
        "      words = calculate_words()\n",
        "    if(len(array) == 0 or len(words) == 0 or depth == 0):\n",
        "      return None\n",
        "    data = next_word_subtree(array, result_array, words)\n",
        "    word = data[0]\n",
        "    words = data[1]\n",
        "    node = Node(word, depth)\n",
        "    node.setP1(calculate_probability_total(result_array))\n",
        "    node.setP0(1-node.p1)\n",
        "    l_num = remove_words(array, word.index, False)\n",
        "    l_array = np.delete(array, l_num, 0)\n",
        "    l_result_array = np.delete(result_array, l_num, 0)\n",
        "    node.setLeftChild(self.anadromi(l_array, l_result_array, depth-1, words.copy()))\n",
        "    r_num = remove_words(array, word.index)\n",
        "    r_array = np.delete(array, r_num, 0)\n",
        "    r_result_array = np.delete(result_array, r_num)\n",
        "    node.setRightChild(self.anadromi(r_array, r_result_array, depth-1, words.copy()))\n",
        "    return node\n",
        "\n",
        "  def fit(self, array, result_array):\n",
        "      self.tree = self.anadromi(array, result_array, self.depth)   \n",
        "\n",
        "  def predict(self, table):\n",
        "    good_result = 0\n",
        "    count = 0\n",
        "    results_array = []\n",
        "    for sentense in table:\n",
        "      tree = self.tree\n",
        "      result = None\n",
        "      while True:\n",
        "        if tree.left == None and tree.right == None or tree.p1 == 1 or tree.p0 == 1:\n",
        "          result = tree\n",
        "          break\n",
        "        else:\n",
        "          sentense_word = findValueFromArray(sentense, tree.value.index)\n",
        "          if(sentense_word == None):\n",
        "            if tree.left == None:\n",
        "              result = tree\n",
        "              break\n",
        "            tree = tree.left\n",
        "          else:\n",
        "            if tree.right == None :\n",
        "              result = tree\n",
        "              break \n",
        "            tree = tree.right\n",
        "      c = 1\n",
        "      if(result.p0 > result.p1):\n",
        "        c = 0\n",
        "      results_array.append(c)\n",
        "    return results_array"
      ],
      "metadata": {
        "id": "khQHB76ruE4P"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "#mabe change the train name \n",
        "def learning_curve(x_binary,y,percentage):\n",
        "  x_part=x_binary[:int(len(x_binary)*percentage)]\n",
        "  y_part=y[:int(len(y)*percentage)]\n",
        "  nb=ID3(100)\n",
        "  nb.fit(x_train_binary[:int(len(x_binary)*percentage)],y_train[:int(len(y)*percentage)])\n",
        "  print(classification_report(y_part, nb.predict(x_part), labels=[0, 1]))"
      ],
      "metadata": {
        "id": "xnUWsNfOyr6i"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arr = x_train_binary[:1000]\n",
        "result_ar = y_train[:1000]\n",
        "\n",
        "learning_curve(arr,result_ar,0.1)\n",
        "learning_curve(arr,result_ar,0.2)\n",
        "learning_curve(arr,result_ar,0.3)\n",
        "learning_curve(arr,result_ar,0.4)\n",
        "learning_curve(arr,result_ar,0.5)\n",
        "learning_curve(arr,result_ar,0.6)\n",
        "learning_curve(arr,result_ar,0.7)\n",
        "learning_curve(arr,result_ar,0.8)\n",
        "learning_curve(arr,result_ar,0.9)\n",
        "learning_curve(arr,result_ar,1)\n",
        "\n",
        "arr = x_test_binary[:1000]\n",
        "result_ar = y_test[:1000]\n",
        "\n",
        "learning_curve(arr,result_ar,0.1)\n",
        "learning_curve(arr,result_ar,0.2)\n",
        "learning_curve(arr,result_ar,0.3)\n",
        "learning_curve(arr,result_ar,0.4)\n",
        "learning_curve(arr,result_ar,0.5)\n",
        "learning_curve(arr,result_ar,0.6)\n",
        "learning_curve(arr,result_ar,0.7)\n",
        "learning_curve(arr,result_ar,0.8)\n",
        "learning_curve(arr,result_ar,0.9)\n",
        "learning_curve(arr,result_ar,1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPm6Aar9yyBG",
        "outputId": "94e2491e-105d-490a-f33f-325d994597a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        58\n",
            "           1       1.00      1.00      1.00        42\n",
            "\n",
            "    accuracy                           1.00       100\n",
            "   macro avg       1.00      1.00      1.00       100\n",
            "weighted avg       1.00      1.00      1.00       100\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.83      0.91       115\n",
            "           1       0.82      1.00      0.90        85\n",
            "\n",
            "    accuracy                           0.91       200\n",
            "   macro avg       0.91      0.92      0.90       200\n",
            "weighted avg       0.92      0.91      0.91       200\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.49      0.66       159\n",
            "           1       0.64      1.00      0.78       141\n",
            "\n",
            "    accuracy                           0.73       300\n",
            "   macro avg       0.82      0.75      0.72       300\n",
            "weighted avg       0.83      0.73      0.71       300\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.69      0.81       204\n",
            "           1       0.75      1.00      0.86       196\n",
            "\n",
            "    accuracy                           0.84       400\n",
            "   macro avg       0.88      0.84      0.84       400\n",
            "weighted avg       0.88      0.84      0.84       400\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.34      0.51       250\n",
            "           1       0.60      1.00      0.75       250\n",
            "\n",
            "    accuracy                           0.67       500\n",
            "   macro avg       0.80      0.67      0.63       500\n",
            "weighted avg       0.80      0.67      0.63       500\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.27      0.43       295\n",
            "           1       0.59      1.00      0.74       305\n",
            "\n",
            "    accuracy                           0.64       600\n",
            "   macro avg       0.79      0.64      0.58       600\n",
            "weighted avg       0.79      0.64      0.59       600\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.31      0.47       347\n",
            "           1       0.60      1.00      0.75       353\n",
            "\n",
            "    accuracy                           0.66       700\n",
            "   macro avg       0.80      0.65      0.61       700\n",
            "weighted avg       0.80      0.66      0.61       700\n",
            "\n"
          ]
        }
      ]
    }
  ]
}