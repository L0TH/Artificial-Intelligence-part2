{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsOzWPK3sQTk"
      },
      "source": [
        "add data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kg6skOVdlPyy",
        "outputId": "b6abc591-8df8-4011-dce2-f176c8a0e454"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n",
            "17473536/17464789 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n",
            "1654784/1641221 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.imdb.load_data(num_words=4000)\n",
        "\n",
        "word_index = tf.keras.datasets.imdb.get_word_index()\n",
        "index2word = dict((i + 3, word) for (word, i) in word_index.items())\n",
        "index2word[0] = '[pad]'\n",
        "index2word[1] = '[bos]'\n",
        "index2word[2] = '[oov]'\n",
        "x_train = np.array([' '.join([index2word[idx] for idx in text]) for text in x_train])\n",
        "x_test = np.array([' '.join([index2word[idx] for idx in text]) for text in x_test])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvyxjs6X1D_3",
        "outputId": "20782752-4937-4a38-b9aa-e8cf3cc347a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3998\n"
          ]
        }
      ],
      "source": [
        "vocabulary = list()\n",
        "for text in x_train:\n",
        "  tokens = text.split()\n",
        "  vocabulary.extend(tokens)\n",
        "\n",
        "vocabulary = set(vocabulary)\n",
        "print(len(vocabulary))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awd5VZ4DzA4-",
        "outputId": "a9501757-0410-4c18-a971-f864fc02e9c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 25000/25000 [06:52<00:00, 60.65it/s]\n",
            "100%|██████████| 25000/25000 [06:41<00:00, 62.26it/s]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "x_train_binary = list()\n",
        "x_test_binary = list()\n",
        "\n",
        "for text in tqdm(x_train):\n",
        "  tokens = text.split()\n",
        "  binary_vector = list()\n",
        "  for vocab_token in vocabulary:\n",
        "    if vocab_token in tokens:\n",
        "      binary_vector.append(1)\n",
        "    else:\n",
        "      binary_vector.append(0)\n",
        "  x_train_binary.append(binary_vector)\n",
        "\n",
        "x_train_binary = np.array(x_train_binary)\n",
        "\n",
        "for text in tqdm(x_test):\n",
        "  tokens = text.split()\n",
        "  binary_vector = list()\n",
        "  for vocab_token in vocabulary:\n",
        "    if vocab_token in tokens:\n",
        "      binary_vector.append(1)\n",
        "    else:\n",
        "      binary_vector.append(0)\n",
        "  x_test_binary.append(binary_vector)\n",
        "\n",
        "x_test_binary = np.array(x_test_binary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEmeqaw4xvxG",
        "outputId": "3c7ed38a-b218-49d5-ce72-030ae94ec70b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0 0 ... 0 0 0]\n",
            "1\n"
          ]
        }
      ],
      "source": [
        "print(x_test_binary[2])\n",
        "print(y_test[2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1imyLLnht0ZU"
      },
      "source": [
        "Exaple for binarytree library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "id": "UyAtAQrrmzTr",
        "outputId": "5b7ce035-84ea-4903-ff53-29f7852c3609"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-cd31bdf13050>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbinarytree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'binarytree'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "from binarytree import Node\n",
        "root = Node(3)\n",
        "root.left = Node(6)\n",
        "root.right = Node(8)\n",
        " \n",
        "# Getting binary tree\n",
        "print('Binary tree :', root)\n",
        " \n",
        "# Getting list of nodes\n",
        "print('List of nodes :', list(root))\n",
        " \n",
        "# Getting inorder of nodes\n",
        "print('Inorder of nodes :', root.inorder)\n",
        " \n",
        "# Checking tree properties\n",
        "print('Size of tree :', root.size)\n",
        "print('Height of tree :', root.height)\n",
        " \n",
        "# Get all properties at once\n",
        "print('Properties of tree : \\n', root.properties)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6vNaFxJO7ya"
      },
      "source": [
        "Calculate entropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "lVXZNBd1NFpd"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from math import log2 \n",
        "\n",
        "def calculate_entropy_total_word(binary_array, c, word, word_position = -1):\n",
        "  first = 0 # c value\n",
        "  second = 0 # other than c value\n",
        "  count = 0 # lengeth\n",
        "  if word_position == -1:\n",
        "    word_position = return_word(word) # the word column\n",
        "\n",
        "  for element in binary_array:\n",
        "      pos = element[word_position]\n",
        "      count += 1\n",
        "      if(pos == c):\n",
        "        first += 1\n",
        "      else:\n",
        "        second += 1\n",
        "  return -(first/count) * math.log2((first/count) - (second/count) * math.log2((second/count)))\n",
        "\n",
        "def calculate_entropy_word(binary_array, c, word, word_position = -1):\n",
        "  first = 0 # c value\n",
        "  second = 0 # other than c value\n",
        "  count = 0 # lengeth\n",
        "\n",
        "  if word_position == -1:\n",
        "    word_position = return_word(word) # the word column\n",
        "  \n",
        "  for element in binary_array:\n",
        "      element = element[word_position]\n",
        "      count += 1\n",
        "      if(element == c):\n",
        "        first += 1\n",
        "      else:\n",
        "        second += 1\n",
        "  try:\n",
        "    return -(first/count) * log2((first/count) - (second/count) * log2((second/count)))\n",
        "  except:\n",
        "    print(word)\n",
        "    return 0\n",
        "\n",
        "\n",
        "def calculate_entropy_total(binary_array, c):\n",
        "  first = 0 # c value\n",
        "  second = 0 # other than c value\n",
        "  count = 0 # lengeth\n",
        "  for element in binary_array:\n",
        "      for pos in element:\n",
        "        count += 1\n",
        "        if(pos == c):\n",
        "          first += 1\n",
        "        else:\n",
        "          second += 1\n",
        "  return -(first/count) * log2((first/count) - (second/count) * log2((second/count)))\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "#print(calculate_entropy_total(x_train_binary, 0))  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jIRutchfXsh"
      },
      "source": [
        "return the position of a word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "yinX5BZncTjX"
      },
      "outputs": [],
      "source": [
        "# -1 = has not found the word\n",
        "def return_word(word):\n",
        "  count = 0\n",
        "  for element in vocabulary:\n",
        "    if word == element:\n",
        "      return count\n",
        "    else:\n",
        "      count += 1\n",
        "  \n",
        "  return -1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cviRH02okRX"
      },
      "source": [
        "calculate probability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "b92d_G8GnLI8"
      },
      "outputs": [],
      "source": [
        "def calculate_probability(array, c, word, word_position = -1):\n",
        "  count = 0\n",
        "  if word_position == -1:\n",
        "    word_position = return_word(word) # the word column\n",
        "  for element in array:\n",
        "    if(element[word_position] == c):\n",
        "      count += 1\n",
        "  return c / len(array)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGM9ktOgVG62"
      },
      "source": [
        "calculate sum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njQ8iEwnVGlw",
        "outputId": "dcde11ce-d140-4269-a964-1954e820d6ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7.734235362941175e-06\n",
            "2.168888473131819e-06\n",
            "-2.7369520781065722e-06\n"
          ]
        }
      ],
      "source": [
        "def calculate_sum(binary_array, word):\n",
        "  word_position = return_word(word)\n",
        "  a = calculate_probability(binary_array, 0, word, word_position) * calculate_entropy_word(binary_array, 0, word,  word_position)\n",
        "  b = calculate_probability(binary_array, 1, word, word_position) * calculate_entropy_word(binary_array, 1, word,  word_position)\n",
        "  return  a + b\n",
        "\n",
        "\n",
        "print(calculate_sum(x_train_binary, \"each\"))\n",
        "print(calculate_sum(x_train_binary,\"transport\"))\n",
        "print(calculate_sum(x_train_binary, \"the\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srdFOxEBVe4v"
      },
      "source": [
        "calculate IG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "vw5xlXQiVguR"
      },
      "outputs": [],
      "source": [
        "def calculate_IG(binary_array, c, word, calculate_entrupy_total = 'no value'):\n",
        "  if calculate_entrupy_total == 'no value':\n",
        "    calculate_entrupy_total = calculate_entropy_total(binary_array, c)\n",
        "  return calculate_entrupy_total - calculate_sum(binary_array, word)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get featured IG\n",
        "\n",
        "We have some problem with 2 words\n"
      ],
      "metadata": {
        "id": "uo-7ZZppO6SF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "def get_featured_max_IG(binary_array, c):\n",
        "  count = 0\n",
        "  a = list()\n",
        "  cet = calculate_entropy_total(binary_array, c)\n",
        "  max = -9^999999999\n",
        "  maxS = \"\"\n",
        "  for x in vocabulary:\n",
        "    count += 1\n",
        "    result = calculate_IG(binary_array,1 , x, cet)\n",
        "    if result > max:\n",
        "      max = result\n",
        "      maxS = x\n",
        "    a.append(calculate_IG(binary_array,1 , x, cet))\n",
        "\n",
        "  print(\"\\n\")\n",
        "  print(\"\\n\")\n",
        "  print(\"\\n\")\n",
        "  return (result, maxS)\n",
        "\n",
        "print(get_featured_max_IG(x_train_binary, 1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0z0NLVggO56z",
        "outputId": "febd5864-0842-4ec9-ea61-a97f6b9870d8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[bos]\n",
            "[bos]\n",
            "[bos]\n",
            "[bos]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "(0.11338480197699137, 'it')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Node"
      ],
      "metadata": {
        "id": "flxeQqSyahtP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Node:\n",
        "  value: int\n",
        "  left = None # must be Node\n",
        "  right = None # must be Node\n",
        "\n",
        "  def __init__(self, v: int = None):\n",
        "    self.value = v\n",
        "  \n",
        "\n",
        "  def setLeftChild(self, v):\n",
        "    self.left = v\n",
        "\n",
        "  def setRightChild(self, v):\n",
        "    self.right  = v\n",
        "\n",
        "  def setChild(self, l, r):\n",
        "    setLeftChild(l)\n",
        "    setRightChild(r)\n",
        "      \n",
        "\n",
        "\n",
        "    #create else\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "hello = Tree(5)\n"
      ],
      "metadata": {
        "id": "W4zpecd3X39Q"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision Tree"
      ],
      "metadata": {
        "id": "rgqEATG5hkBX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DecisionTreeClassifier(object):\n",
        "    def __init__(self, max_depth):\n",
        "        self.depth = 0\n",
        "        self.max_depth = max_depth\n",
        "    \n",
        "    def fit(self, x, y, par_node={}, depth=0):\n",
        "        if par_node is None: \n",
        "            return Noneg\n",
        "        elif len(y) == 0:\n",
        "            return None\n",
        "        elif self.all_same(y):\n",
        "            return {'val':y[0]}\n",
        "        elif depth >= self.max_depth:\n",
        "            return None\n",
        "        else: \n",
        "            col, cutoff, entropy = self.find_best_split_of_all(x, y)    # find one split given an information gain \n",
        "            y_left = y[x[:, col] < cutoff]\n",
        "            y_right = y[x[:, col] >= cutoff]\n",
        "            par_node = {'col': iris.feature_names[col], 'index_col':col,\n",
        "                        'cutoff':cutoff,\n",
        "                       'val': np.round(np.mean(y))}\n",
        "            par_node['left'] = self.fit(x[x[:, col] < cutoff], y_left, {}, depth+1)\n",
        "            par_node['right'] = self.fit(x[x[:, col] >= cutoff], y_right, {}, depth+1)\n",
        "            self.depth += 1 \n",
        "            self.trees = par_node\n",
        "            return par_node\n",
        "    \n",
        "    def find_best_split_of_all(self, x, y):\n",
        "        col = None\n",
        "        min_entropy = 1\n",
        "        cutoff = None\n",
        "        for i, c in enumerate(x.T):\n",
        "            entropy, cur_cutoff = self.find_best_split(c, y)\n",
        "            if entropy == 0:    # find the first perfect cutoff. Stop Iterating\n",
        "                return i, cur_cutoff, entropy\n",
        "            elif entropy <= min_entropy:\n",
        "                min_entropy = entropy\n",
        "                col = i\n",
        "                cutoff = cur_cutoff\n",
        "        return col, cutoff, min_entropy\n",
        "    \n",
        "    def find_best_split(self, col, y):\n",
        "        min_entropy = 10\n",
        "        n = len(y)\n",
        "        for value in set(col):\n",
        "            y_predict = col < value\n",
        "            my_entropy = get_entropy(y_predict, y)\n",
        "            if my_entropy <= min_entropy:\n",
        "                min_entropy = my_entropy\n",
        "                cutoff = value\n",
        "        return min_entropy, cutoff\n",
        "    \n",
        "    def all_same(self, items):\n",
        "        return all(x == items[0] for x in items)\n",
        "                                           \n",
        "    def predict(self, x):\n",
        "        tree = self.trees\n",
        "        results = np.array([0]*len(x))\n",
        "        for i, c in enumerate(x):\n",
        "            results[i] = self._get_prediction(c)\n",
        "        return results\n",
        "    \n",
        "    def _get_prediction(self, row):\n",
        "        cur_layer = self.trees\n",
        "        while cur_layer.get('cutoff'):\n",
        "            if row[cur_layer['index_col']] < cur_layer['cutoff']:\n",
        "                cur_layer = cur_layer['left']\n",
        "            else:\n",
        "                cur_layer = cur_layer['right']\n",
        "        else:\n",
        "            return cur_layer.get('val')\n",
        "\n",
        "    def predict(self, X):\n",
        "        return [self._predict(inputs) for inputs in X]\n",
        "\n",
        "    def _predict(self, inputs):\n",
        "        \"\"\"Predict class for a single sample.\"\"\"\n",
        "        node = self.tree_\n",
        "        while node.left:\n",
        "            if inputs[node.feature_index] < node.threshold:\n",
        "                node = node.left\n",
        "            else:\n",
        "                node = node.right\n",
        "        return node.predicted_class\n"
      ],
      "metadata": {
        "id": "vrdI_6vQhnkF"
      },
      "execution_count": 3,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "ID3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}