{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsOzWPK3sQTk"
      },
      "source": [
        "add data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kg6skOVdlPyy",
        "outputId": "8afae5cf-0027-4fd2-cd0c-785d76357bd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n",
            "17473536/17464789 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n",
            "1654784/1641221 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.imdb.load_data(num_words=4000)\n",
        "\n",
        "word_index = tf.keras.datasets.imdb.get_word_index()\n",
        "index2word = dict((i + 3, word) for (word, i) in word_index.items())\n",
        "index2word[0] = '[pad]'\n",
        "index2word[1] = '[bos]'\n",
        "index2word[2] = '[oov]'\n",
        "x_train = np.array([' '.join([index2word[idx] for idx in text]) for text in x_train])\n",
        "x_test = np.array([' '.join([index2word[idx] for idx in text]) for text in x_test])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvyxjs6X1D_3",
        "outputId": "adabdc4c-2009-4e8f-ef51-3feec80cd062"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3998\n"
          ]
        }
      ],
      "source": [
        "vocabulary = list()\n",
        "for text in x_train:\n",
        "  tokens = text.split()\n",
        "  vocabulary.extend(tokens)\n",
        "\n",
        "vocabulary = set(vocabulary)\n",
        "print(len(vocabulary))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awd5VZ4DzA4-",
        "outputId": "f74d51aa-1e92-4c95-a4c0-ea26b78f8f5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 25000/25000 [07:27<00:00, 55.88it/s]\n",
            "100%|██████████| 25000/25000 [07:17<00:00, 57.13it/s]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "x_train_binary = list()\n",
        "x_test_binary = list()\n",
        "\n",
        "for text in tqdm(x_train):\n",
        "  tokens = text.split()\n",
        "  binary_vector = list()\n",
        "  for vocab_token in vocabulary:\n",
        "    if vocab_token in tokens:\n",
        "      binary_vector.append(1)\n",
        "    else:\n",
        "      binary_vector.append(0)\n",
        "  x_train_binary.append(binary_vector)\n",
        "\n",
        "x_train_binary = np.array(x_train_binary)\n",
        "\n",
        "for text in tqdm(x_test):\n",
        "  tokens = text.split()\n",
        "  binary_vector = list()\n",
        "  for vocab_token in vocabulary:\n",
        "    if vocab_token in tokens:\n",
        "      binary_vector.append(1)\n",
        "    else:\n",
        "      binary_vector.append(0)\n",
        "  x_test_binary.append(binary_vector)\n",
        "\n",
        "x_test_binary = np.array(x_test_binary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEmeqaw4xvxG",
        "outputId": "72bba297-d896-48a6-d46a-788c8dc51faf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 0 0 ... 0 0 0]\n",
            "1\n",
            "[0 0 0 ... 0 0 0]\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "print(x_test_binary[2])\n",
        "print(y_test[2])\n",
        "print(x_train_binary[2])\n",
        "print(y_train[2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6vNaFxJO7ya"
      },
      "source": [
        "Calculate entropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "lVXZNBd1NFpd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e171ea85-b2df-441a-c751-acff6e321e43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.1133869708654645\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "from math import log2 \n",
        "\n",
        "def calculate_entropy_total_word(binary_array, c, word, word_position = -1):\n",
        "  first = 0 # c value\n",
        "  second = 0 # other than c value\n",
        "  count = 0 # lengeth\n",
        "  if word_position == -1:\n",
        "    word_position = return_word(word) # the word column\n",
        "\n",
        "  for element in binary_array:\n",
        "      pos = element[word_position]\n",
        "      count += 1\n",
        "      if(pos == c):\n",
        "        first += 1\n",
        "      else:\n",
        "        second += 1\n",
        "  return -(first/count) * math.log2((first/count) - (second/count) * math.log2((second/count)))\n",
        "\n",
        "def calculate_entropy_word(binary_array, c, word, word_position = -1):\n",
        "  first = 0 # c value\n",
        "  second = 0 # other than c value\n",
        "  count = 0 # lengeth\n",
        "\n",
        "  if word_position == -1:\n",
        "    word_position = return_word(word) # the word column\n",
        "  \n",
        "  for element in binary_array:\n",
        "      element = element[word_position]\n",
        "      count += 1\n",
        "      if(element == c):\n",
        "        first += 1\n",
        "      else:\n",
        "        second += 1\n",
        "  \n",
        "  val = -(first/count) * log2((first/count) - (second/count) * log2((second/count)))\n",
        "  return val\n",
        "\n",
        "\n",
        "def calculate_entropy_total(binary_array):\n",
        "  first = 0 # c value\n",
        "  second = 0 # other than c value\n",
        "  count = 0 # lengeth\n",
        "  for element in binary_array:\n",
        "      for pos in element:\n",
        "        count += 1\n",
        "        if(pos == 1):\n",
        "          first += 1\n",
        "        else:\n",
        "          second += 1\n",
        "  return -(first/count) * log2((first/count) - (second/count) * log2((second/count)))\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "print(calculate_entropy_total(x_train_binary))  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jIRutchfXsh"
      },
      "source": [
        "return the position of a word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "yinX5BZncTjX"
      },
      "outputs": [],
      "source": [
        "# -1 = has not found the word\n",
        "def return_word(word):\n",
        "  count = 0\n",
        "  for element in vocabulary:\n",
        "    if word == element:\n",
        "      return count\n",
        "    else:\n",
        "      count += 1\n",
        "  \n",
        "  return -1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cviRH02okRX"
      },
      "source": [
        "calculate probability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "b92d_G8GnLI8"
      },
      "outputs": [],
      "source": [
        "def calculate_probability_old(array, c, word, word_position = -1):\n",
        "  count = 0\n",
        "  if word_position == -1:\n",
        "    word_position = return_word(word) # the word column\n",
        "  for element in array:\n",
        "    if(element[word_position] == c):\n",
        "      count += 1\n",
        "  return count / len(array)\n",
        "\n",
        "\n",
        "\n",
        "def calculate_probability(array, c, word, word_position = -1):\n",
        "  count = 0\n",
        "  p = 0\n",
        "  index = 0\n",
        "  if word_position == -1:\n",
        "    word_position = return_word(word) # the word column\n",
        "  for element in array:\n",
        "    if(element[word_position] == 1):\n",
        "      count += 1\n",
        "      if(y_train[index] == c):\n",
        "        p += 1\n",
        "    index += 1\n",
        "  return p / count"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGM9ktOgVG62"
      },
      "source": [
        "calculate sum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "njQ8iEwnVGlw"
      },
      "outputs": [],
      "source": [
        "def calculate_sum(binary_array, word):\n",
        "  try:\n",
        "    word_position = word.index\n",
        "    p0 = (calculate_probability_old(binary_array, 0, word, word_position))\n",
        "    p1 = (calculate_probability_old(binary_array, 1, word, word_position))\n",
        "    word.setEntropy0(calculate_entropy_word(binary_array, 0, word,  word_position))\n",
        "    word.setEntropy1(calculate_entropy_word(binary_array, 1, word,  word_position))\n",
        "    a = p0 * word.entropy0\n",
        "    b = p1 * word.entropy1\n",
        "    return  a + b\n",
        "  except:\n",
        "    return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srdFOxEBVe4v"
      },
      "source": [
        "calculate IG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "vw5xlXQiVguR"
      },
      "outputs": [],
      "source": [
        "def calculate_IG(binary_array, c, word, calculate_entrupy_total = 'no value'):\n",
        "  if calculate_entrupy_total == 'no value':\n",
        "    calculate_entrupy_total = calculate_entropy_total(binary_array)\n",
        "  try:\n",
        "    word.setIg(calculate_entrupy_total - calculate_sum(binary_array, word))\n",
        "  except:\n",
        "    word.setIg(None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uo-7ZZppO6SF"
      },
      "source": [
        "Get featured IG\n",
        "\n",
        "We have some problem with 2 words\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0z0NLVggO56z"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "def get_featured_max_IG(binary_array, c):\n",
        "  count = 0\n",
        "  a = list()\n",
        "  cet = calculate_entropy_total(binary_array)\n",
        "  max = -9^999999999\n",
        "  maxS = \"\"\n",
        "  for x in vocabulary:\n",
        "    count += 1\n",
        "    try:\n",
        "      result = calculate_IG(binary_array,1 , x, cet)\n",
        "      if result > max:\n",
        "        max = result\n",
        "        maxS = x\n",
        "      a.append(calculate_IG(binary_array,1 , x, cet))\n",
        "    except:\n",
        "      continue\n",
        "\n",
        "  print(\"\\n\")\n",
        "  print(\"\\n\")\n",
        "  print(\"\\n\")\n",
        "  return (result, maxS)\n",
        "\n",
        "print(get_featured_max_IG(x_train_binary, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "AQ_HScftv6J2"
      },
      "outputs": [],
      "source": [
        "class Word:\n",
        "\n",
        "  def __init__(self, value:str, index:int):\n",
        "    self.value = value\n",
        "    self.index = index\n",
        "    self.p0 = None\n",
        "    self.p1 = None\n",
        "    self.ig = None\n",
        "    self.entropy0 = None\n",
        "    self.entropy1 = None\n",
        "\n",
        "\n",
        "  def setP0(self, p0):\n",
        "    self.p0 = p0\n",
        "  \n",
        "  def setP1(self, p1):\n",
        "    self.p1 = p1\n",
        "  \n",
        "  def setIg(self, ig):\n",
        "    if(ig != None):\n",
        "      self.ig = float(ig)\n",
        "\n",
        "  def setEntropy0(self, entropy0):\n",
        "    self.entropy0 = entropy0\n",
        "\n",
        "  def setEntropy1(self, entropy1):\n",
        "    self.entropy1  = entropy1\n",
        "\n",
        "  def __str__(self):\n",
        "    return self.value\n",
        "\n",
        "  def __repr__(self):\n",
        "    return self.value + \" \" + str(self.ig)\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flxeQqSyahtP"
      },
      "source": [
        "Node"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "W4zpecd3X39Q"
      },
      "outputs": [],
      "source": [
        "class Node:\n",
        "  value: Word\n",
        "  left: Node = None # must be Node\n",
        "  right: Node = None # must be Node\n",
        "\n",
        "  def __init__(self, v: int = None):\n",
        "    self.value = v\n",
        "  \n",
        "  def setLeftChild(self, v):\n",
        "    self.left = v\n",
        "\n",
        "  def setRightChild(self, v):\n",
        "    self.right  = v\n",
        "\n",
        "  def setChilds(self, l, r):\n",
        "    self.setLeftChild(l)\n",
        "    self.setRightChild(r)\n",
        "\n",
        "  def __str__(self):\n",
        "    return self.value.value\n",
        "      \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7d48TpzqULq"
      },
      "source": [
        "Remove words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "Qav_EFbBqT1T"
      },
      "outputs": [],
      "source": [
        "def hasTheWord(word1: Word, word2: Word):\n",
        "  index1 = int(word1.index)\n",
        "  index2 = int(word2.index)\n",
        "  for x in x_train_binary:\n",
        "    if(x[index1] == 1 and x[index2] == 1):\n",
        "      return 1\n",
        "  return 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "J8dyqz8W0ey5"
      },
      "outputs": [],
      "source": [
        "#there is the word in the setence\n",
        "def findValueFromArray(array, index):\n",
        "  if len(array) < index:\n",
        "    return None\n",
        "  count = 0\n",
        "  for x in array:\n",
        "    if(count == index):\n",
        "      return x\n",
        "    count+= 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "W-NJOe03lbpx"
      },
      "outputs": [],
      "source": [
        "def findTheNextWord(maxWord, array, c):\n",
        "  nextWord = array.pop()\n",
        "  while hasTheWord(maxWord, nextWord) != c:\n",
        "    if len(array) == 0:\n",
        "      return None\n",
        "    try:\n",
        "      nextWord = array.pop()\n",
        "    except:\n",
        "      return None\n",
        "  return nextWord"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDhSVIjz-qh9"
      },
      "source": [
        "create words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "M8PdAlrq-nKl"
      },
      "outputs": [],
      "source": [
        "test = x_train_binary[0]\n",
        "ar = x_train_binary.tolist()\n",
        "i = 0\n",
        "et = calculate_entropy_total(x_train_binary)\n",
        "words = list()\n",
        "for x in vocabulary:\n",
        "  words.append(Word(x, i))\n",
        "  i+= 1\n",
        "words_to_remove = list()\n",
        "for word in words:\n",
        "  calculate_IG(x_train_binary, 1, word, et)\n",
        "  word.setP0(calculate_probability(x_train_binary, 0, word, word.index))\n",
        "  word.setP1(calculate_probability(x_train_binary, 1, word, word.index))\n",
        "  if(word.ig == None):\n",
        "    words_to_remove.append(word)\n",
        "\n",
        "\n",
        "\n",
        "for x in words_to_remove:\n",
        "  words.remove(x)\n",
        "\n",
        "words.sort(key=lambda x: x.ig, reverse=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "try with node"
      ],
      "metadata": {
        "id": "Tdc4HRNs6fO6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wordsNodes = Node(words.pop())\n",
        "while len(words) > 0:\n",
        "  wor = words.pop()\n",
        "  nod = wordsNodes\n",
        "  while True:\n",
        "    if hasTheWord(wor, nod.value) == 1:\n",
        "      if nod.right == None:\n",
        "        nod.setRightChild(Node(wor))\n",
        "        break\n",
        "      else:\n",
        "        nod = nod.right\n",
        "    else:\n",
        "      if nod.left == None:\n",
        "        nod.setLeftChild(Node(wor))\n",
        "        break\n",
        "      else:\n",
        "        nod = nod.left\n",
        "\n",
        "\n",
        "print(wordsNodes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_t2AFF-Rq7Su",
        "outputId": "3b8e16ef-58bc-4f1f-dc6f-2ec0d2a6be8b"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "an\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "good_result = 0\n",
        "count = 0\n",
        "for sentense in x_test_binary:\n",
        "  tree = wordsNodes\n",
        "  result = None\n",
        "  while True:\n",
        "    if(tree.value.p0 == 1 or tree.value.p1 == 0 or (tree.left == None and tree.right == None)):\n",
        "      result = tree.value\n",
        "      break\n",
        "    else:\n",
        "      sentense_word = findValueFromArray(sentense, tree.value.index)\n",
        "      if(sentense_word == None):\n",
        "        if(tree.left == None):\n",
        "          result = tree.value\n",
        "          break\n",
        "        tree = tree.left\n",
        "      else:\n",
        "        if(tree.right == None):\n",
        "          result = tree.value\n",
        "          break\n",
        "        tree = tree.right\n",
        "  if(result.p0 > result.p1 and y_test[count] == 0):\n",
        "    good_result += 1\n",
        "  elif (result.p0 < result.p1 and y_test[count] == 1):\n",
        "    good_result += 1\n",
        "  count += 1\n",
        "  if(count == 1000):\n",
        "    break\n",
        "  if(count % 100 == 1):\n",
        "    print(good_result/count*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEq5ZPcV6ebr",
        "outputId": "4afa4df5-b9fc-4feb-ccbb-a003f331c994"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100.0\n",
            "46.53465346534654\n",
            "54.72636815920397\n",
            "52.823920265780735\n",
            "51.87032418952619\n",
            "52.29540918163673\n",
            "50.41597337770383\n",
            "52.06847360912982\n",
            "52.30961298377028\n",
            "52.497225305216425\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "ID3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}