{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsOzWPK3sQTk"
      },
      "source": [
        "add data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kg6skOVdlPyy",
        "outputId": "aa9ff13f-cb40-417d-cee1-558b1ec0dd9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n",
            "17473536/17464789 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n",
            "1654784/1641221 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.imdb.load_data(num_words=4000)\n",
        "\n",
        "word_index = tf.keras.datasets.imdb.get_word_index()\n",
        "index2word = dict((i + 3, word) for (word, i) in word_index.items())\n",
        "index2word[0] = '[pad]'\n",
        "index2word[1] = '[bos]'\n",
        "index2word[2] = '[oov]'\n",
        "x_train = np.array([' '.join([index2word[idx] for idx in text]) for text in x_train])\n",
        "x_test = np.array([' '.join([index2word[idx] for idx in text]) for text in x_test])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvyxjs6X1D_3",
        "outputId": "c109f6fd-179d-44e1-b2ba-e4c2e3d76d5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3998\n"
          ]
        }
      ],
      "source": [
        "vocabulary = list()\n",
        "for text in x_train:\n",
        "  tokens = text.split()\n",
        "  vocabulary.extend(tokens)\n",
        "\n",
        "vocabulary = set(vocabulary)\n",
        "print(len(vocabulary))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awd5VZ4DzA4-",
        "outputId": "c253444c-6994-4a49-8b47-36574741ea6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 25000/25000 [07:11<00:00, 57.93it/s]\n",
            "100%|██████████| 25000/25000 [06:56<00:00, 60.04it/s]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "x_train_binary = list()\n",
        "x_test_binary = list()\n",
        "\n",
        "for text in tqdm(x_train):\n",
        "  tokens = text.split()\n",
        "  binary_vector = list()\n",
        "  for vocab_token in vocabulary:\n",
        "    if vocab_token in tokens:\n",
        "      binary_vector.append(1)\n",
        "    else:\n",
        "      binary_vector.append(0)\n",
        "  x_train_binary.append(binary_vector)\n",
        "\n",
        "x_train_binary = np.array(x_train_binary)\n",
        "\n",
        "for text in tqdm(x_test):\n",
        "  tokens = text.split()\n",
        "  binary_vector = list()\n",
        "  for vocab_token in vocabulary:\n",
        "    if vocab_token in tokens:\n",
        "      binary_vector.append(1)\n",
        "    else:\n",
        "      binary_vector.append(0)\n",
        "  x_test_binary.append(binary_vector)\n",
        "\n",
        "x_test_binary = np.array(x_test_binary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEmeqaw4xvxG",
        "outputId": "72bba297-d896-48a6-d46a-788c8dc51faf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 0 0 ... 0 0 0]\n",
            "1\n",
            "[0 0 0 ... 0 0 0]\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "print(x_test_binary[2])\n",
        "print(y_test[2])\n",
        "print(x_train_binary[2])\n",
        "print(y_train[2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6vNaFxJO7ya"
      },
      "source": [
        "Calculate entropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "lVXZNBd1NFpd"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from math import log2 \n",
        "\n",
        "def calculate_entropy_total_word(binary_array, c, word, word_position = -1):\n",
        "  first = 0 # c value\n",
        "  second = 0 # other than c value\n",
        "  count = 0 # lengeth\n",
        "  if word_position == -1:\n",
        "    word_position = return_word(word) # the word column\n",
        "\n",
        "  for element in binary_array:\n",
        "      pos = element[word_position]\n",
        "      count += 1\n",
        "      if(pos == c):\n",
        "        first += 1\n",
        "      else:\n",
        "        second += 1\n",
        "  return -(first/count) * math.log2((first/count) - (second/count) * math.log2((second/count)))\n",
        "\n",
        "def calculate_entropy_word(binary_array, c, word, word_position = -1):\n",
        "  first = 0 # c value\n",
        "  second = 0 # other than c value\n",
        "  count = 0 # lengeth\n",
        "\n",
        "  if word_position == -1:\n",
        "    word_position = return_word(word) # the word column\n",
        "  \n",
        "  for element in binary_array:\n",
        "      element = element[word_position]\n",
        "      count += 1\n",
        "      if(element == c):\n",
        "        first += 1\n",
        "      else:\n",
        "        second += 1\n",
        "  \n",
        "  val = -(first/count) * log2((first/count) - (second/count) * log2((second/count)))\n",
        "  return val\n",
        "\n",
        "\n",
        "def calculate_entropy_total(binary_array, c):\n",
        "  first = 0 # c value\n",
        "  second = 0 # other than c value\n",
        "  count = 0 # lengeth\n",
        "  for element in binary_array:\n",
        "      for pos in element:\n",
        "        count += 1\n",
        "        if(pos == c):\n",
        "          first += 1\n",
        "        else:\n",
        "          second += 1\n",
        "  return -(first/count) * log2((first/count) - (second/count) * log2((second/count)))\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "#print(calculate_entropy_total(x_train_binary, 0))  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jIRutchfXsh"
      },
      "source": [
        "return the position of a word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "yinX5BZncTjX"
      },
      "outputs": [],
      "source": [
        "# -1 = has not found the word\n",
        "def return_word(word):\n",
        "  count = 0\n",
        "  for element in vocabulary:\n",
        "    if word == element:\n",
        "      return count\n",
        "    else:\n",
        "      count += 1\n",
        "  \n",
        "  return -1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cviRH02okRX"
      },
      "source": [
        "calculate probability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "b92d_G8GnLI8"
      },
      "outputs": [],
      "source": [
        "def calculate_probability_old(array, c, word, word_position = -1):\n",
        "  count = 0\n",
        "  if word_position == -1:\n",
        "    word_position = return_word(word) # the word column\n",
        "  for element in array:\n",
        "    if(element[word_position] == c):\n",
        "      count += 1\n",
        "  return count / len(array)\n",
        "\n",
        "\n",
        "\n",
        "def calculate_probability(array, c, word, word_position = -1):\n",
        "  count = 0\n",
        "  p = 0\n",
        "  index = 0\n",
        "  if word_position == -1:\n",
        "    word_position = return_word(word) # the word column\n",
        "  for element in array:\n",
        "    if(element[word_position] == 1):\n",
        "      count += 1\n",
        "      if(y_train[index] == c):\n",
        "        p += 1\n",
        "    index += 1\n",
        "  return p / count"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGM9ktOgVG62"
      },
      "source": [
        "calculate sum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "njQ8iEwnVGlw"
      },
      "outputs": [],
      "source": [
        "def calculate_sum(binary_array, word):\n",
        "  try:\n",
        "    word_position = word.index\n",
        "    p0 = (calculate_probability_old(binary_array, 0, word, word_position))\n",
        "    p1 = (calculate_probability_old(binary_array, 1, word, word_position))\n",
        "    word.setEntropy0(calculate_entropy_word(binary_array, 0, word,  word_position))\n",
        "    word.setEntropy1(calculate_entropy_word(binary_array, 1, word,  word_position))\n",
        "    a = p0 * word.entropy0\n",
        "    b = p1 * word.entropy1\n",
        "    return  a + b\n",
        "  except:\n",
        "    return None\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srdFOxEBVe4v"
      },
      "source": [
        "calculate IG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "vw5xlXQiVguR"
      },
      "outputs": [],
      "source": [
        "def calculate_IG(binary_array, c, word, calculate_entrupy_total = 'no value'):\n",
        "  if calculate_entrupy_total == 'no value':\n",
        "    calculate_entrupy_total = calculate_entropy_total(binary_array, c)\n",
        "  try:\n",
        "    word.setIg(calculate_entrupy_total - calculate_sum(binary_array, word))\n",
        "  except:\n",
        "    word.setIg(None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uo-7ZZppO6SF"
      },
      "source": [
        "Get featured IG\n",
        "\n",
        "We have some problem with 2 words\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0z0NLVggO56z"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "def get_featured_max_IG(binary_array, c):\n",
        "  count = 0\n",
        "  a = list()\n",
        "  cet = calculate_entropy_total(binary_array, c)\n",
        "  max = -9^999999999\n",
        "  maxS = \"\"\n",
        "  for x in vocabulary:\n",
        "    count += 1\n",
        "    try:\n",
        "      result = calculate_IG(binary_array,1 , x, cet)\n",
        "      if result > max:\n",
        "        max = result\n",
        "        maxS = x\n",
        "      a.append(calculate_IG(binary_array,1 , x, cet))\n",
        "    except:\n",
        "      continue\n",
        "\n",
        "  print(\"\\n\")\n",
        "  print(\"\\n\")\n",
        "  print(\"\\n\")\n",
        "  return (result, maxS)\n",
        "\n",
        "print(get_featured_max_IG(x_train_binary, 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flxeQqSyahtP"
      },
      "source": [
        "Node"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4zpecd3X39Q",
        "outputId": "a5d99eab-515b-4431-b851-d65c96bae5b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n"
          ]
        }
      ],
      "source": [
        "class Node:\n",
        "  value: int\n",
        "  p0: int\n",
        "  p1: int\n",
        "  left = None # must be Node\n",
        "  right = None # must be Node\n",
        "\n",
        "  def __init__(self, v: int = None):\n",
        "    self.value = v\n",
        "  \n",
        "  def setLeftChild(self, v):\n",
        "    self.left = v\n",
        "\n",
        "  def setRightChild(self, v):\n",
        "    self.right  = v\n",
        "\n",
        "  def setChilds(self, l, r):\n",
        "    self.setLeftChild(l)\n",
        "    self.setRightChild(r)\n",
        "  def result(self):\n",
        "    if(p0 > p1):\n",
        "      return \"positive\"\n",
        "    return \"negative\"\n",
        "  def __str__(self):\n",
        "    return str(self.value)\n",
        "      \n",
        "\n",
        "\n",
        "h = Node(5)\n",
        "h.setLeftChild(Node(3))\n",
        "print(h)\n",
        "\n",
        "\n",
        "    #create else"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7d48TpzqULq"
      },
      "source": [
        "Remove words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Qav_EFbBqT1T"
      },
      "outputs": [],
      "source": [
        "def hasTheWord(word1: Word, word2: Word):\n",
        "  index1 =word1.index\n",
        "  index2 = word2.index\n",
        "  for x in x_train_binary:\n",
        "    if(x[index1] == 1 and x[index2] == 1):\n",
        "      return 1\n",
        "\n",
        "  return 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "AQ_HScftv6J2"
      },
      "outputs": [],
      "source": [
        "class Word:\n",
        "\n",
        "  def __init__(self, value:str, index:int):\n",
        "    self.value = value\n",
        "    self.index = index\n",
        "    self.p0 = None\n",
        "    self.p1 = None\n",
        "    self.ig = None\n",
        "    self.entropy0 = None\n",
        "    self.entropy1 = None\n",
        "\n",
        "\n",
        "  def setP0(self, p0):\n",
        "    self.p0 = p0\n",
        "  \n",
        "  def setP1(self, p1):\n",
        "    self.p1 = p1\n",
        "  \n",
        "  def setIg(self, ig):\n",
        "    if(ig != None):\n",
        "      self.ig = float(ig)\n",
        "\n",
        "  def setEntropy0(self, entropy0):\n",
        "    self.entropy0 = entropy0\n",
        "\n",
        "  def setEntropy1(self, entropy1):\n",
        "    self.entropy1  = entropy1\n",
        "\n",
        "  def __str__(self):\n",
        "    return self.ig\n",
        "\n",
        "  def __repr__(self):\n",
        "    return self.value + \" \" + str(self.ig)\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "J8dyqz8W0ey5"
      },
      "outputs": [],
      "source": [
        "#there is the word in the setence\n",
        "def findValueFromArray(array, index):\n",
        "  if len(array) < index:\n",
        "    return None\n",
        "  count = 0\n",
        "  for x in array:\n",
        "    if(count == index):\n",
        "      return x\n",
        "    count+= 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "W-NJOe03lbpx"
      },
      "outputs": [],
      "source": [
        "def findTheNextWord(maxWord, array, c):\n",
        "  nextWord = array.pop()\n",
        "  while hasTheWord(maxWord, nextWord) != c:\n",
        "    if len(array) == 0:\n",
        "      return None\n",
        "    try:\n",
        "      nextWord = array.pop()\n",
        "    except:\n",
        "      return None\n",
        "  return nextWord"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgqEATG5hkBX"
      },
      "source": [
        "Main run one"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "id": "vrdI_6vQhnkF",
        "outputId": "88fea263-8523-4791-f5bf-4223536437c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-94adb8c18be9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train_binary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0met\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_entropy_total\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_binary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-7a1b86cb6152>\u001b[0m in \u001b[0;36mcalculate_entropy_total\u001b[0;34m(binary_array, c)\u001b[0m\n\u001b[1;32m     45\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mpos\u001b[0m \u001b[0;32min\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m           \u001b[0mfirst\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "test = x_train_binary[0]\n",
        "print(y_train[0])\n",
        "ar = x_train_binary.tolist()\n",
        "i = 0\n",
        "et = calculate_entropy_total(x_train_binary, 1)\n",
        "words = list()\n",
        "for x in vocabulary:\n",
        "  words.append(Word(x, i))\n",
        "  i+= 1\n",
        "words_to_remove = list()\n",
        "for word in words:\n",
        "  calculate_IG(x_train_binary, 1, word, et)\n",
        "  word.setP0(calculate_probability(x_train_binary, 0, word, word.index))\n",
        "  word.setP1(calculate_probability(x_train_binary, 1, word, word.index))\n",
        "  if(word.ig == None):\n",
        "    words_to_remove.append(word)\n",
        "\n",
        "\n",
        "\n",
        "for x in words_to_remove:\n",
        "  words.remove(x)\n",
        "\n",
        "\n",
        "\n",
        "words.sort(key=lambda x: x.ig, reverse=True)\n",
        "max = words.pop()\n",
        "stopTheWhile = False\n",
        "#next = findTheNextWord(max, words, c)\n",
        "while len(words) !=0 and not stopTheWhile:\n",
        "  c = findValueFromArray(test, max.index)\n",
        "  while len(words) != 0 and max.p0 != 1 and max.p1 !=1:\n",
        "    next = findTheNextWord(max, words, c)\n",
        "    if(next == None):\n",
        "      stopTheWhile = True\n",
        "      break\n",
        "    max = next\n",
        "\n",
        "\n",
        "if(max.p0 > max.p1):\n",
        "  print(\"bad\")\n",
        "  print(max.p0)\n",
        "  print(max.p1)\n",
        "else:\n",
        "  print(\"good\")\n",
        "  print(max.p0)\n",
        "  print(max.p1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDhSVIjz-qh9"
      },
      "source": [
        "create words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "M8PdAlrq-nKl"
      },
      "outputs": [],
      "source": [
        "test = x_train_binary[0]\n",
        "ar = x_train_binary.tolist()\n",
        "i = 0\n",
        "et = calculate_entropy_total(x_train_binary, 1)\n",
        "words = list()\n",
        "for x in vocabulary:\n",
        "  words.append(Word(x, i))\n",
        "  i+= 1\n",
        "words_to_remove = list()\n",
        "for word in words:\n",
        "  calculate_IG(x_train_binary, 1, word, et)\n",
        "  word.setP0(calculate_probability(x_train_binary, 0, word, word.index))\n",
        "  word.setP1(calculate_probability(x_train_binary, 1, word, word.index))\n",
        "  if(word.ig == None):\n",
        "    words_to_remove.append(word)\n",
        "\n",
        "\n",
        "\n",
        "for x in words_to_remove:\n",
        "  words.remove(x)\n",
        "\n",
        "\n",
        "\n",
        "words.sort(key=lambda x: x.ig, reverse=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run it all"
      ],
      "metadata": {
        "id": "wVd1HEgZYZxz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcMAfMSt4W5v",
        "outputId": "eca45079-0f40-4c70-8cac-f2d4e40bf9eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello let's start\n",
            "48.0\n"
          ]
        }
      ],
      "source": [
        "j = 0\n",
        "#next = findTheNextWord(max, words, c)\n",
        "good_result = 0\n",
        "print(\"hello let's start\")\n",
        "for sentense in x_train_binary:\n",
        "  copy_words = words.copy()\n",
        "  max = copy_words.pop()\n",
        "  stopTheWhile = False\n",
        "  while len(copy_words) !=0 and not stopTheWhile:\n",
        "    c = findValueFromArray(sentense, max.index)\n",
        "    while len(copy_words) != 0 and max.p0 != 1 and max.p1 !=1:\n",
        "      next = findTheNextWord(max, copy_words, c)\n",
        "      if(next == None):\n",
        "        stopTheWhile = True\n",
        "        break\n",
        "      max = next\n",
        "  if(max.p0 > max.p1):\n",
        "    if 0 == y_train[j]:\n",
        "      good_result += 1\n",
        "  else:\n",
        "    if 1 == y_train[j]:\n",
        "      good_result += 1\n",
        "\n",
        "  j+=1\n",
        "  if(j%100 == 0):\n",
        "    print(good_result/j*100)\n",
        "\n",
        "\n",
        "\n",
        "print(\"teliko\")\n",
        "print(good_result/j*100)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "ID3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}