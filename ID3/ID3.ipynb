{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsOzWPK3sQTk"
      },
      "source": [
        "add data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kg6skOVdlPyy",
        "outputId": "e63b84a3-d3b7-4ec8-c45a-26ae6a71c3fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n",
            "17473536/17464789 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n",
            "1654784/1641221 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.imdb.load_data(num_words=4000)\n",
        "\n",
        "word_index = tf.keras.datasets.imdb.get_word_index()\n",
        "index2word = dict((i + 3, word) for (word, i) in word_index.items())\n",
        "index2word[0] = '[pad]'\n",
        "index2word[1] = '[bos]'\n",
        "index2word[2] = '[oov]'\n",
        "x_train = np.array([' '.join([index2word[idx] for idx in text]) for text in x_train])\n",
        "x_test = np.array([' '.join([index2word[idx] for idx in text]) for text in x_test])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvyxjs6X1D_3",
        "outputId": "caf2447f-5099-4f86-e56c-564c05a906dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3998\n"
          ]
        }
      ],
      "source": [
        "vocabulary = list()\n",
        "for text in x_train:\n",
        "  tokens = text.split()\n",
        "  vocabulary.extend(tokens)\n",
        "\n",
        "vocabulary = set(vocabulary)\n",
        "print(len(vocabulary))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awd5VZ4DzA4-",
        "outputId": "eece48cb-0b99-4f5e-c4fe-f58d5cdbd4f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 25000/25000 [07:33<00:00, 55.07it/s]\n",
            "100%|██████████| 25000/25000 [07:24<00:00, 56.25it/s]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "x_train_binary = list()\n",
        "x_test_binary = list()\n",
        "\n",
        "for text in tqdm(x_train):\n",
        "  tokens = text.split()\n",
        "  binary_vector = list()\n",
        "  for vocab_token in vocabulary:\n",
        "    if vocab_token in tokens:\n",
        "      binary_vector.append(1)\n",
        "    else:\n",
        "      binary_vector.append(0)\n",
        "  x_train_binary.append(binary_vector)\n",
        "\n",
        "x_train_binary = np.array(x_train_binary)\n",
        "\n",
        "for text in tqdm(x_test):\n",
        "  tokens = text.split()\n",
        "  binary_vector = list()\n",
        "  for vocab_token in vocabulary:\n",
        "    if vocab_token in tokens:\n",
        "      binary_vector.append(1)\n",
        "    else:\n",
        "      binary_vector.append(0)\n",
        "  x_test_binary.append(binary_vector)\n",
        "\n",
        "x_test_binary = np.array(x_test_binary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEmeqaw4xvxG",
        "outputId": "3c7ed38a-b218-49d5-ce72-030ae94ec70b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0 0 ... 0 0 0]\n",
            "1\n"
          ]
        }
      ],
      "source": [
        "print(x_test_binary[2])\n",
        "print(y_test[2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1imyLLnht0ZU"
      },
      "source": [
        "Exaple for binarytree library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "id": "UyAtAQrrmzTr",
        "outputId": "cd99b653-0a0f-49fd-870c-2fce51b76673"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-cd31bdf13050>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbinarytree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'binarytree'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "from binarytree import Node\n",
        "root = Node(3)\n",
        "root.left = Node(6)\n",
        "root.right = Node(8)\n",
        " \n",
        "# Getting binary tree\n",
        "print('Binary tree :', root)\n",
        " \n",
        "# Getting list of nodes\n",
        "print('List of nodes :', list(root))\n",
        " \n",
        "# Getting inorder of nodes\n",
        "print('Inorder of nodes :', root.inorder)\n",
        " \n",
        "# Checking tree properties\n",
        "print('Size of tree :', root.size)\n",
        "print('Height of tree :', root.height)\n",
        " \n",
        "# Get all properties at once\n",
        "print('Properties of tree : \\n', root.properties)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6vNaFxJO7ya"
      },
      "source": [
        "Calculate entropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "lVXZNBd1NFpd"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from math import log2 \n",
        "\n",
        "def calculate_entropy_total_word(binary_array, c, word, word_position = -1):\n",
        "  first = 0 # c value\n",
        "  second = 0 # other than c value\n",
        "  count = 0 # lengeth\n",
        "  if word_position == -1:\n",
        "    word_position = return_word(word) # the word column\n",
        "\n",
        "  for element in binary_array:\n",
        "      pos = element[word_position]\n",
        "      count += 1\n",
        "      if(pos == c):\n",
        "        first += 1\n",
        "      else:\n",
        "        second += 1\n",
        "  return -(first/count) * math.log2((first/count) - (second/count) * math.log2((second/count)))\n",
        "\n",
        "def calculate_entropy_word(binary_array, c, word, word_position = -1):\n",
        "  first = 0 # c value\n",
        "  second = 0 # other than c value\n",
        "  count = 0 # lengeth\n",
        "\n",
        "  if word_position == -1:\n",
        "    word_position = return_word(word) # the word column\n",
        "  \n",
        "  for element in binary_array:\n",
        "      element = element[word_position]\n",
        "      count += 1\n",
        "      if(element == c):\n",
        "        first += 1\n",
        "      else:\n",
        "        second += 1\n",
        "  try:\n",
        "    return -(first/count) * log2((first/count) - (second/count) * log2((second/count)))\n",
        "  except:\n",
        "    print(word)\n",
        "    return 0\n",
        "\n",
        "\n",
        "def calculate_entropy_total(binary_array, c):\n",
        "  first = 0 # c value\n",
        "  second = 0 # other than c value\n",
        "  count = 0 # lengeth\n",
        "  for element in binary_array:\n",
        "      for pos in element:\n",
        "        count += 1\n",
        "        if(pos == c):\n",
        "          first += 1\n",
        "        else:\n",
        "          second += 1\n",
        "  return -(first/count) * log2((first/count) - (second/count) * log2((second/count)))\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "#print(calculate_entropy_total(x_train_binary, 0))  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jIRutchfXsh"
      },
      "source": [
        "return the position of a word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "yinX5BZncTjX"
      },
      "outputs": [],
      "source": [
        "# -1 = has not found the word\n",
        "def return_word(word):\n",
        "  count = 0\n",
        "  for element in vocabulary:\n",
        "    if word == element:\n",
        "      return count\n",
        "    else:\n",
        "      count += 1\n",
        "  \n",
        "  return -1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cviRH02okRX"
      },
      "source": [
        "calculate probability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "b92d_G8GnLI8"
      },
      "outputs": [],
      "source": [
        "def calculate_probability(array, c, word, word_position = -1):\n",
        "  count = 0\n",
        "  if word_position == -1:\n",
        "    word_position = return_word(word) # the word column\n",
        "  for element in array:\n",
        "    if(element[word_position] == c):\n",
        "      count += 1\n",
        "  return c / len(array)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGM9ktOgVG62"
      },
      "source": [
        "calculate sum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njQ8iEwnVGlw",
        "outputId": "539f6002-d0bf-4ac8-a45a-f637893b2c27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7.734235362941175e-06\n",
            "1.3492780685311555e-06\n",
            "-2.7369520781065722e-06\n"
          ]
        }
      ],
      "source": [
        "def calculate_sum(binary_array, word):\n",
        "  word_position = return_word(word)\n",
        "  a = calculate_probability(binary_array, 0, word, word_position) * calculate_entropy_word(binary_array, 0, word,  word_position)\n",
        "  b = calculate_probability(binary_array, 1, word, word_position) * calculate_entropy_word(binary_array, 1, word,  word_position)\n",
        "  return  a + b\n",
        "\n",
        "\n",
        "print(calculate_sum(x_train_binary, \"each\"))\n",
        "print(calculate_sum(x_train_binary,\"transport\"))\n",
        "print(calculate_sum(x_train_binary, \"the\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srdFOxEBVe4v"
      },
      "source": [
        "calculate IG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "vw5xlXQiVguR"
      },
      "outputs": [],
      "source": [
        "def calculate_IG(binary_array, c, word, calculate_entrupy_total = 'no value'):\n",
        "  if calculate_entrupy_total == 'no value':\n",
        "    calculate_entrupy_total = calculate_entropy_total(binary_array, c)\n",
        "  return calculate_entrupy_total - calculate_sum(binary_array, word)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get featured IG\n",
        "\n",
        "We have some problem with 2 words\n"
      ],
      "metadata": {
        "id": "uo-7ZZppO6SF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "def get_featured_max_IG(binary_array, c):\n",
        "  count = 0\n",
        "  a = list()\n",
        "  cet = calculate_entropy_total(binary_array, c)\n",
        "  max = -9^999999999\n",
        "  maxS = \"\"\n",
        "  for x in vocabulary:\n",
        "    count += 1\n",
        "    result = calculate_IG(binary_array,1 , x, cet)\n",
        "    if result > max:\n",
        "      result = max\n",
        "      maxS = x\n",
        "    a.append(calculate_IG(binary_array,1 , x, cet))\n",
        "\n",
        "  print(\"\\n\")\n",
        "  print(\"\\n\")\n",
        "  print(\"\\n\")\n",
        "  return (result, maxS)\n",
        "\n",
        "print(get_featured_max_IG(x_train_binary, 1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0z0NLVggO56z",
        "outputId": "336ed8a9-e6eb-4d6b-d97c-cb96b2efd7db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[bos]\n",
            "[bos]\n",
            "[bos]\n",
            "[bos]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision Tree"
      ],
      "metadata": {
        "id": "flxeQqSyahtP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DecisionTree:\n",
        "  def __init__(self, binary_array, c)\n",
        "    self.node = None"
      ],
      "metadata": {
        "id": "aN0TQKJbak_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGllwokshXIp"
      },
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "ID3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}