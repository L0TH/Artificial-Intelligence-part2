{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsOzWPK3sQTk"
      },
      "source": [
        "add data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Kg6skOVdlPyy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "553222e2-aa6e-4df1-e744-9d037bcbf801"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n",
            "17473536/17464789 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n",
            "1654784/1641221 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.imdb.load_data(num_words=4000)\n",
        "\n",
        "word_index = tf.keras.datasets.imdb.get_word_index()\n",
        "index2word = dict((i + 3, word) for (word, i) in word_index.items())\n",
        "index2word[0] = '[pad]'\n",
        "index2word[1] = '[bos]'\n",
        "index2word[2] = '[oov]'\n",
        "x_train = np.array([' '.join([index2word[idx] for idx in text]) for text in x_train])\n",
        "x_test = np.array([' '.join([index2word[idx] for idx in text]) for text in x_test])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvyxjs6X1D_3",
        "outputId": "afd3a892-1345-4966-eb56-a27bc7b2b88d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3998\n"
          ]
        }
      ],
      "source": [
        "vocabulary = list()\n",
        "for text in x_train:\n",
        "  tokens = text.split()\n",
        "  vocabulary.extend(tokens)\n",
        "\n",
        "vocabulary = set(vocabulary)\n",
        "print(len(vocabulary))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awd5VZ4DzA4-",
        "outputId": "c5bd525d-56b5-47df-c1e0-c4a6a7066e1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 25000/25000 [07:17<00:00, 57.10it/s]\n",
            "100%|██████████| 25000/25000 [07:06<00:00, 58.59it/s]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "x_train_binary = list()\n",
        "x_test_binary = list()\n",
        "\n",
        "for text in tqdm(x_train):\n",
        "  tokens = text.split()\n",
        "  binary_vector = list()\n",
        "  for vocab_token in vocabulary:\n",
        "    if vocab_token in tokens:\n",
        "      binary_vector.append(1)\n",
        "    else:\n",
        "      binary_vector.append(0)\n",
        "  x_train_binary.append(binary_vector)\n",
        "\n",
        "x_train_binary = np.array(x_train_binary)\n",
        "\n",
        "for text in tqdm(x_test):\n",
        "  tokens = text.split()\n",
        "  binary_vector = list()\n",
        "  for vocab_token in vocabulary:\n",
        "    if vocab_token in tokens:\n",
        "      binary_vector.append(1)\n",
        "    else:\n",
        "      binary_vector.append(0)\n",
        "  x_test_binary.append(binary_vector)\n",
        "\n",
        "x_test_binary = np.array(x_test_binary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEmeqaw4xvxG",
        "outputId": "72bba297-d896-48a6-d46a-788c8dc51faf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 ... 0 0 0]\n",
            "1\n",
            "[0 0 0 ... 0 0 0]\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "print(x_test_binary[2])\n",
        "print(y_test[2])\n",
        "print(x_train_binary[2])\n",
        "print(y_train[2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6vNaFxJO7ya"
      },
      "source": [
        "Calculate entropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "lVXZNBd1NFpd"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from math import log2 \n",
        "\n",
        "def calculate_entropy_total_word(binary_array, c, word, word_position = -1):\n",
        "  first = 0 # c value\n",
        "  second = 0 # other than c value\n",
        "  count = 0 # lengeth\n",
        "  if word_position == -1:\n",
        "    word_position = return_word(word) # the word column\n",
        "\n",
        "  for element in binary_array:\n",
        "      pos = element[word_position]\n",
        "      count += 1\n",
        "      if(pos == c):\n",
        "        first += 1\n",
        "      else:\n",
        "        second += 1\n",
        "  return -(first/count) * math.log2((first/count) - (second/count) * math.log2((second/count)))\n",
        "\n",
        "def calculate_entropy_word(binary_array, c, word, word_position = -1):\n",
        "  first = 0 # c value\n",
        "  second = 0 # other than c value\n",
        "  count = 0 # lengeth\n",
        "\n",
        "  if word_position == -1:\n",
        "    word_position = return_word(word) # the word column\n",
        "  \n",
        "  for element in binary_array:\n",
        "      element = element[word_position]\n",
        "      count += 1\n",
        "      if(element == c):\n",
        "        first += 1\n",
        "      else:\n",
        "        second += 1\n",
        "  \n",
        "  val = -(first/count) * log2((first/count) - (second/count) * log2((second/count)))\n",
        "  return val\n",
        "\n",
        "\n",
        "def calculate_entropy_total(binary_array, c):\n",
        "  first = 0 # c value\n",
        "  second = 0 # other than c value\n",
        "  count = 0 # lengeth\n",
        "  for element in binary_array:\n",
        "      for pos in element:\n",
        "        count += 1\n",
        "        if(pos == c):\n",
        "          first += 1\n",
        "        else:\n",
        "          second += 1\n",
        "  return -(first/count) * log2((first/count) - (second/count) * log2((second/count)))\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "#print(calculate_entropy_total(x_train_binary, 0))  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "DUZHwQQYnIDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jIRutchfXsh"
      },
      "source": [
        "return the position of a word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "yinX5BZncTjX"
      },
      "outputs": [],
      "source": [
        "# -1 = has not found the word\n",
        "def return_word(word):\n",
        "  count = 0\n",
        "  for element in vocabulary:\n",
        "    if word == element:\n",
        "      return count\n",
        "    else:\n",
        "      count += 1\n",
        "  \n",
        "  return -1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cviRH02okRX"
      },
      "source": [
        "calculate probability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "b92d_G8GnLI8"
      },
      "outputs": [],
      "source": [
        "def calculate_probability(array, c, word, word_position = -1):\n",
        "  count = 0\n",
        "  if word_position == -1:\n",
        "    word_position = return_word(word) # the word column\n",
        "  for element in array:\n",
        "    if(element[word_position] == c):\n",
        "      count += 1\n",
        "  return count / len(array)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGM9ktOgVG62"
      },
      "source": [
        "calculate sum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "njQ8iEwnVGlw"
      },
      "outputs": [],
      "source": [
        "def calculate_sum(binary_array, word):\n",
        "  try:\n",
        "    word_position = word.index\n",
        "    word.setP0(calculate_probability(binary_array, 0, word, word_position))\n",
        "    word.setP1(calculate_probability(binary_array, 1, word, word_position))\n",
        "    word.setEntropy0(calculate_entropy_word(binary_array, 0, word,  word_position))\n",
        "    word.setEntropy1(calculate_entropy_word(binary_array, 1, word,  word_position))\n",
        "    a = word.p0 * word.entropy0\n",
        "    b = word.p1 * word.entropy1\n",
        "    return  a + b\n",
        "  except:\n",
        "    return None\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srdFOxEBVe4v"
      },
      "source": [
        "calculate IG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "vw5xlXQiVguR"
      },
      "outputs": [],
      "source": [
        "def calculate_IG(binary_array, c, word, calculate_entrupy_total = 'no value'):\n",
        "  if calculate_entrupy_total == 'no value':\n",
        "    calculate_entrupy_total = calculate_entropy_total(binary_array, c)\n",
        "  try:\n",
        "    word.setIg(calculate_entrupy_total - calculate_sum(binary_array, word))\n",
        "  except:\n",
        "    word.setIg(None)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get featured IG\n",
        "\n",
        "We have some problem with 2 words\n"
      ],
      "metadata": {
        "id": "uo-7ZZppO6SF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "def get_featured_max_IG(binary_array, c):\n",
        "  count = 0\n",
        "  a = list()\n",
        "  cet = calculate_entropy_total(binary_array, c)\n",
        "  max = -9^999999999\n",
        "  maxS = \"\"\n",
        "  for x in vocabulary:\n",
        "    count += 1\n",
        "    try:\n",
        "      result = calculate_IG(binary_array,1 , x, cet)\n",
        "      if result > max:\n",
        "        max = result\n",
        "        maxS = x\n",
        "      a.append(calculate_IG(binary_array,1 , x, cet))\n",
        "    except:\n",
        "      continue\n",
        "\n",
        "  print(\"\\n\")\n",
        "  print(\"\\n\")\n",
        "  print(\"\\n\")\n",
        "  return (result, maxS)\n",
        "\n",
        "print(get_featured_max_IG(x_train_binary, 1))"
      ],
      "metadata": {
        "id": "0z0NLVggO56z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Node"
      ],
      "metadata": {
        "id": "flxeQqSyahtP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Node:\n",
        "  value: int\n",
        "  p0: int\n",
        "  p1: int\n",
        "  left = None # must be Node\n",
        "  right = None # must be Node\n",
        "\n",
        "  def __init__(self, v: int = None):\n",
        "    self.value = v\n",
        "  \n",
        "  def setLeftChild(self, v):\n",
        "    self.left = v\n",
        "\n",
        "  def setRightChild(self, v):\n",
        "    self.right  = v\n",
        "\n",
        "  def setChilds(self, l, r):\n",
        "    self.setLeftChild(l)\n",
        "    self.setRightChild(r)\n",
        "  def result(self):\n",
        "    if(p0 > p1):\n",
        "      return \"positive\"\n",
        "    return \"negative\"\n",
        "  def __str__(self):\n",
        "    return str(self.value)\n",
        "      \n",
        "\n",
        "\n",
        "h = Node(5)\n",
        "h.setLeftChild(Node(3))\n",
        "print(h)\n",
        "\n",
        "\n",
        "    #create else"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4zpecd3X39Q",
        "outputId": "60ea9b40-48ae-480a-8a68-27e7f384fb59"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remove words"
      ],
      "metadata": {
        "id": "x7d48TpzqULq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def hasTheWord(word1: Word, word2: Word):\n",
        "  index1 =word1.index\n",
        "  index2 = word2.index\n",
        "  for x in x_train_binary:\n",
        "    if(x[index1] == 1 and x[index2] == 1):\n",
        "      return 1\n",
        "\n",
        "  return 0\n"
      ],
      "metadata": {
        "id": "Qav_EFbBqT1T"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Word:\n",
        "\n",
        "  def __init__(self, value:str, index:int):\n",
        "    self.value = value\n",
        "    self.index = index\n",
        "    self.p0 = None\n",
        "    self.p1 = None\n",
        "    self.ig = None\n",
        "    self.entropy0 = None\n",
        "    self.entropy1 = None\n",
        "\n",
        "\n",
        "  def setP0(self, p0):\n",
        "    self.p0 = p0\n",
        "  \n",
        "  def setP1(self, p1):\n",
        "    self.p1 = p1\n",
        "  \n",
        "  def setIg(self, ig):\n",
        "    if(ig != None):\n",
        "      self.ig = float(ig)\n",
        "\n",
        "  def setEntropy0(self, entropy0):\n",
        "    self.entropy0 = entropy0\n",
        "\n",
        "  def setEntropy1(self, entropy1):\n",
        "    self.entropy1  = entropy1\n",
        "\n",
        "  def __str__(self):\n",
        "    return self.ig\n",
        "\n",
        "  def __repr__(self):\n",
        "    return self.value + \" \" + str(self.ig)\n",
        "  "
      ],
      "metadata": {
        "id": "AQ_HScftv6J2"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#there is the word in the setence\n",
        "def findValueFromArray(array, index):\n",
        "  if len(array) < index:\n",
        "    return None\n",
        "  count = 0\n",
        "  for x in array:\n",
        "    if(count == index):\n",
        "      return x\n",
        "    count+= 1"
      ],
      "metadata": {
        "id": "J8dyqz8W0ey5"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def findTheNextWord(maxWord, array, c):\n",
        "  nextWord = array.pop()\n",
        "  while hasTheWord(maxWord, nextWord) != c:\n",
        "    if len(array) == 0:\n",
        "      return None\n",
        "    nextWord = array.pop()\n",
        "  return nextWord"
      ],
      "metadata": {
        "id": "W-NJOe03lbpx"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Main"
      ],
      "metadata": {
        "id": "rgqEATG5hkBX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test = x_train_binary[0]\n",
        "print(y_train[0])\n",
        "ar = x_train_binary.tolist()\n",
        "i = 0\n",
        "et = calculate_entropy_total(x_train_binary, 1)\n",
        "words = list()\n",
        "for x in vocabulary:\n",
        "  words.append(Word(x, i))\n",
        "  i+= 1\n",
        "words_to_remove = list()\n",
        "for word in words:\n",
        "  calculate_IG(x_train_binary, 1, word, et)\n",
        "  if(word.ig == None):\n",
        "    words_to_remove.append(word)\n",
        "\n",
        "\n",
        "\n",
        "for x in words_to_remove:\n",
        "  words.remove(x)\n",
        "\n",
        "\n",
        "\n",
        "words.sort(key=lambda x: x.ig, reverse=True)\n",
        "max = words.pop()\n",
        "stopTheWhile = False\n",
        "#next = findTheNextWord(max, words, c)\n",
        "while len(words) !=0 and not stopTheWhile:\n",
        "  c = findValueFromArray(test, max.index)\n",
        "  while len(words) != 0 and max.p0 != 1 and max.p1 !=1:\n",
        "    next = findTheNextWord(max, words, c)\n",
        "    if(next == None):\n",
        "      stopTheWhile = True\n",
        "      break\n",
        "    max = next\n",
        "\n",
        "\n",
        "if(max.p0 > max.p1):\n",
        "  print(\"bad\")\n",
        "  print(max.p0)\n",
        "  print(max.p1)\n",
        "else:\n",
        "  print(\"good\")\n",
        "  print(max.p0)\n",
        "  print(max.p1)\n",
        "\n"
      ],
      "metadata": {
        "id": "vrdI_6vQhnkF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76f63231-d1ee-4855-bf0d-7b6c17d7f2c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "ID3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}