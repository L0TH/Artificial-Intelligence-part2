{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ID3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "add data"
      ],
      "metadata": {
        "id": "YsOzWPK3sQTk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "Kg6skOVdlPyy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bcd6e77-4984-4d62-8fb9-e3bfb33e48b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n",
            "17473536/17464789 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n",
            "1654784/1641221 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.imdb.load_data(num_words=4000)\n",
        "\n",
        "word_index = tf.keras.datasets.imdb.get_word_index()\n",
        "index2word = dict((i + 3, word) for (word, i) in word_index.items())\n",
        "index2word[0] = '[pad]'\n",
        "index2word[1] = '[bos]'\n",
        "index2word[2] = '[oov]'\n",
        "x_train = np.array([' '.join([index2word[idx] for idx in text]) for text in x_train])\n",
        "x_test = np.array([' '.join([index2word[idx] for idx in text]) for text in x_test])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary = list()\n",
        "for text in x_train:\n",
        "  tokens = text.split()\n",
        "  vocabulary.extend(tokens)\n",
        "\n",
        "vocabulary = set(vocabulary)\n",
        "print(len(vocabulary))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvyxjs6X1D_3",
        "outputId": "293179b7-d276-4fa9-a73d-59e8d399ecb0"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3998\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "x_train_binary = list()\n",
        "x_test_binary = list()\n",
        "\n",
        "for text in tqdm(x_train):\n",
        "  tokens = text.split()\n",
        "  binary_vector = list()\n",
        "  for vocab_token in vocabulary:\n",
        "    if vocab_token in tokens:\n",
        "      binary_vector.append(1)\n",
        "    else:\n",
        "      binary_vector.append(0)\n",
        "  x_train_binary.append(binary_vector)\n",
        "\n",
        "x_train_binary = np.array(x_train_binary)\n",
        "\n",
        "for text in tqdm(x_test):\n",
        "  tokens = text.split()\n",
        "  binary_vector = list()\n",
        "  for vocab_token in vocabulary:\n",
        "    if vocab_token in tokens:\n",
        "      binary_vector.append(1)\n",
        "    else:\n",
        "      binary_vector.append(0)\n",
        "  x_test_binary.append(binary_vector)\n",
        "\n",
        "x_test_binary = np.array(x_test_binary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awd5VZ4DzA4-",
        "outputId": "a23258bb-5b7e-4a61-f118-c76a89a2eacb"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 25000/25000 [07:17<00:00, 57.18it/s]\n",
            "100%|██████████| 25000/25000 [07:10<00:00, 58.02it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_test_binary[2])\n",
        "print(y_test[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEmeqaw4xvxG",
        "outputId": "d1685ac2-6287-42ea-af32-73ee1cd5809d"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 ... 0 0 0]\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exaple for binarytree library"
      ],
      "metadata": {
        "id": "1imyLLnht0ZU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from binarytree import Node\n",
        "root = Node(3)\n",
        "root.left = Node(6)\n",
        "root.right = Node(8)\n",
        " \n",
        "# Getting binary tree\n",
        "print('Binary tree :', root)\n",
        " \n",
        "# Getting list of nodes\n",
        "print('List of nodes :', list(root))\n",
        " \n",
        "# Getting inorder of nodes\n",
        "print('Inorder of nodes :', root.inorder)\n",
        " \n",
        "# Checking tree properties\n",
        "print('Size of tree :', root.size)\n",
        "print('Height of tree :', root.height)\n",
        " \n",
        "# Get all properties at once\n",
        "print('Properties of tree : \\n', root.properties)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyAtAQrrmzTr",
        "outputId": "b41e5a0a-59ff-4ef7-d7e8-2e1762430ed4"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Binary tree : \n",
            "  3\n",
            " / \\\n",
            "6   8\n",
            "\n",
            "List of nodes : [Node(3), Node(6), Node(8)]\n",
            "Inorder of nodes : [Node(6), Node(3), Node(8)]\n",
            "Size of tree : 3\n",
            "Height of tree : 1\n",
            "Properties of tree : \n",
            " {'height': 1, 'size': 3, 'is_max_heap': False, 'is_min_heap': True, 'is_perfect': True, 'is_strict': True, 'is_complete': True, 'leaf_count': 2, 'min_node_value': 3, 'max_node_value': 8, 'min_leaf_depth': 1, 'max_leaf_depth': 1, 'is_balanced': True, 'is_bst': False, 'is_symmetric': False}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate entropy"
      ],
      "metadata": {
        "id": "l6vNaFxJO7ya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from math import log2 \n",
        "\n",
        "def calculate_entropy_total_word(binary_array, c, word, word_position = -1):\n",
        "  first = 0 # c value\n",
        "  second = 0 # other than c value\n",
        "  count = 0 # lengeth\n",
        "  if word_position == -1:\n",
        "    word_position = return_word(word) # the word column\n",
        "\n",
        "  for element in binary_array:\n",
        "      pos = element[word_position]\n",
        "      count += 1\n",
        "      if(pos == c):\n",
        "        first += 1\n",
        "      else:\n",
        "        second += 1\n",
        "  return -(first/count) * log2((first/count) - (second/count) * log2((second/count)))\n",
        "\n",
        "def calculate_entropy_word(binary_array, c, word, word_position = -1):\n",
        "  first = 0 # c value\n",
        "  second = 0 # other than c value\n",
        "  count = 0 # lengeth\n",
        "\n",
        "  if word_position == -1:\n",
        "    word_position = return_word(word) # the word column\n",
        "  \n",
        "  for element in binary_array:\n",
        "      element = element[word_position]\n",
        "      count += 1\n",
        "      if(element == c):\n",
        "        first += 1\n",
        "      else:\n",
        "        second += 1\n",
        "  return -(first/count) * log2((first/count) - (second/count) * log2((second/count)))\n",
        "\n",
        "\n",
        "def calculate_entropy_total(binary_array, c):\n",
        "  first = 0 # c value\n",
        "  second = 0 # other than c value\n",
        "  count = 0 # lengeth\n",
        "  for element in binary_array:\n",
        "      for pos in element:\n",
        "        count += 1\n",
        "        if(pos == c):\n",
        "          first += 1\n",
        "        else:\n",
        "          second += 1\n",
        "  return -(first/count) * log2((first/count) - (second/count) * log2((second/count)))\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "print(calculate_entropy_total(x_train_binary, 0))  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVXZNBd1NFpd",
        "outputId": "e29e0b60-6274-44fe-99d0-9f9d4315e9ad"
      },
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-0.1606486478356765\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "return the position of a word"
      ],
      "metadata": {
        "id": "5jIRutchfXsh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -1 = has not found the word\n",
        "def return_word(word):\n",
        "  count = 0\n",
        "  for element in vocabulary:\n",
        "    if word == element:\n",
        "      return count\n",
        "    else:\n",
        "      count += 1\n",
        "  \n",
        "  return -1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yinX5BZncTjX",
        "outputId": "64aab697-50d1-4574-d685-ab3a6a40fa74"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "calculate probability"
      ],
      "metadata": {
        "id": "4cviRH02okRX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_probability(array, c, word, word_position = -1):\n",
        "  count = 0\n",
        "  if word_position == -1:\n",
        "    word_position = return_word(word) # the word column\n",
        "  for element in array:\n",
        "    if(element[word_position] == c):\n",
        "      count += 1\n",
        "  return c / len(array)"
      ],
      "metadata": {
        "id": "b92d_G8GnLI8"
      },
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "calculate sum"
      ],
      "metadata": {
        "id": "cGM9ktOgVG62"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_sum(binary_array, word):\n",
        "  word_position = return_word(word)\n",
        "  a = calculate_probability(binary_array, 0, word, word_position) * calculate_entropy_word(binary_array, 0, word,  word_position)\n",
        "  b = calculate_probability(binary_array, 1, word, word_position) * calculate_entropy_word(binary_array, 1, word,  word_position)\n",
        "  return  a + b\n",
        "\n",
        "\n",
        "print(calculate_sum(x_train_binary, \"each\"))\n",
        "print(calculate_sum(x_train_binary,\"transport\"))\n",
        "print(calculate_sum(x_train_binary, \"the\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njQ8iEwnVGlw",
        "outputId": "0bffd6ec-a874-4e52-c434-c6f0b2a8af2c"
      },
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7.734235362941175e-06\n",
            "4.367466433054744e-06\n",
            "-2.7369520781065722e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "calculate IG"
      ],
      "metadata": {
        "id": "srdFOxEBVe4v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_IG(binary_array, c, word):\n",
        "  return calculate_entropy_total(binary_array, c) - calculate_sum(binary_array, word)\n",
        "\n",
        "print(1)\n",
        "print(calculate_IG(x_train_binary, 1, \"a\"))\n",
        "print(calculate_IG(x_train_binary, 1, \"the\"))\n",
        "print(calculate_IG(x_train_binary, 1, \"me\"))\n",
        "print(calculate_IG(x_train_binary, 1, \"we\"))\n",
        "print(calculate_IG(x_train_binary, 1, \"each\"))\n",
        "print(0)\n",
        "print(calculate_IG(x_train_binary, 0, \"a\"))\n",
        "print(calculate_IG(x_train_binary, 0, \"the\"))\n",
        "print(calculate_IG(x_train_binary, 0, \"me\"))\n",
        "print(calculate_IG(x_train_binary, 0, \"we\"))\n",
        "print(calculate_IG(x_train_binary, 0, \"each\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vw5xlXQiVguR",
        "outputId": "350c3ed4-b5b7-4e94-fe09-61eb8c361e06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "0.11339376629839994\n",
            "0.1133897078175426\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZGllwokshXIp"
      }
    }
  ]
}