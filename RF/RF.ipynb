{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsOzWPK3sQTk"
      },
      "source": [
        "add data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kg6skOVdlPyy",
        "outputId": "f6007961-7ece-416c-8bd0-50753002cb5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n",
            "17473536/17464789 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n",
            "1654784/1641221 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.imdb.load_data(num_words=4000)\n",
        "\n",
        "word_index = tf.keras.datasets.imdb.get_word_index()\n",
        "index2word = dict((i + 3, word) for (word, i) in word_index.items())\n",
        "index2word[0] = '[pad]'\n",
        "index2word[1] = '[bos]'\n",
        "index2word[2] = '[oov]'\n",
        "x_train = np.array([' '.join([index2word[idx] for idx in text]) for text in x_train])\n",
        "x_test = np.array([' '.join([index2word[idx] for idx in text]) for text in x_test])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvyxjs6X1D_3",
        "outputId": "d3b5c670-8ae3-4a42-a9c7-0f322b5b5761"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3998\n"
          ]
        }
      ],
      "source": [
        "vocabulary = list()\n",
        "for text in x_train:\n",
        "  tokens = text.split()\n",
        "  vocabulary.extend(tokens)\n",
        "\n",
        "vocabulary = set(vocabulary)\n",
        "print(len(vocabulary))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awd5VZ4DzA4-",
        "outputId": "be8214c7-29c5-4ad5-d7eb-7d9162d406b5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 25000/25000 [07:26<00:00, 56.01it/s]\n",
            "100%|██████████| 25000/25000 [07:19<00:00, 56.83it/s]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "x_train_binary = list()\n",
        "x_test_binary = list()\n",
        "\n",
        "for text in tqdm(x_train):\n",
        "  tokens = text.split()\n",
        "  binary_vector = list()\n",
        "  for vocab_token in vocabulary:\n",
        "    if vocab_token in tokens:\n",
        "      binary_vector.append(1)\n",
        "    else:\n",
        "      binary_vector.append(0)\n",
        "  x_train_binary.append(binary_vector)\n",
        "\n",
        "x_train_binary = np.array(x_train_binary)\n",
        "\n",
        "for text in tqdm(x_test):\n",
        "  tokens = text.split()\n",
        "  binary_vector = list()\n",
        "  for vocab_token in vocabulary:\n",
        "    if vocab_token in tokens:\n",
        "      binary_vector.append(1)\n",
        "    else:\n",
        "      binary_vector.append(0)\n",
        "  x_test_binary.append(binary_vector)\n",
        "\n",
        "x_test_binary = np.array(x_test_binary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "NUqjmNPYPEPF"
      },
      "outputs": [],
      "source": [
        "def predictRF(array_2d):\n",
        "  np_2d_array = np.array(array_2d)\n",
        "  \n",
        "  midenika = np.count_nonzero(np_2d_array==0, axis=0)\n",
        "  assoi = np.count_nonzero(np_2d_array==1, axis=0)\n",
        "\n",
        "  toReturn = list()\n",
        "  print(len(np_2d_array[0]))\n",
        "  for i in range(len(np_2d_array[0])):\n",
        "    if midenika[i] > assoi[i]:\n",
        "      toReturn.append(0)\n",
        "    elif assoi[i] > midenika[i]:\n",
        "      toReturn.append(1)\n",
        "    elif assoi[i] == midenika[i]:\n",
        "      toReturn.append(0)\n",
        "    \n",
        "  return toReturn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CntF0sUe4TK"
      },
      "source": [
        "ID3 class - Not working"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rOFM9pjQGfrj"
      },
      "outputs": [],
      "source": [
        "class ID3:\n",
        "    def __init__(self, x_tr_bin:list(), y_tr:list(), wor:list()):\n",
        "        self.x_tr_bin = x_tr_bin\n",
        "        self.y_tr = y_tr\n",
        "        self.wor  = wor\n",
        "\n",
        "    def run(self):\n",
        "      j = 0 #next = findTheNextWord(max, words, c)\n",
        "      good_result = 0\n",
        "      print('------------------------------stolou------- len(self.x_tr_bin)', len(self.x_tr_bin))\n",
        "      print(\"------------------------------stolou------- hello let's start\")\n",
        "      print(self.wor)\n",
        "      for sentense in self.x_tr_bin:\n",
        "        print('!!@@@@!!@!@!@protash')\n",
        "        copy_words = self.wor.copy()\n",
        "        max = copy_words.pop()\n",
        "        stopTheWhile = False\n",
        "        while len(copy_words) !=0 and not stopTheWhile:\n",
        "          c = findValueFromArray(sentense, max.index)\n",
        "          while len(copy_words) != 0 and max.p0 != 1 and max.p1 !=1:\n",
        "            next = findTheNextWord(max, copy_words, c)\n",
        "            if(next == None):\n",
        "              stopTheWhile = True\n",
        "              break\n",
        "            max = next\n",
        "        if(max.p0 > max.p1):\n",
        "          if 0 == self.y_tr[j]:\n",
        "            good_result += 1\n",
        "        else:\n",
        "          if 1 == self.y_tr[j]:\n",
        "            good_result += 1\n",
        "\n",
        "        j+=1\n",
        "        \n",
        "        print('------------------------------stolou------- ', good_result/j*100)\n",
        "      return good_result/j*100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQWm1a7yezRg"
      },
      "source": [
        "Run ID3 class - Not working"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rE0TZa4YGnJO"
      },
      "outputs": [],
      "source": [
        "id3Obj = ID3(x_train_binary, y_train, words)\n",
        "id3Obj.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqRNsvnGKyTu"
      },
      "source": [
        "RF me ID3 Gianni"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "AqDj2RshK28Q"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from random import randint\n",
        "\n",
        "# numOfTrees = 3 # (x_train_binary) * 0.3)\n",
        "def ourRF(x_train, y_train, words, numOfTrees):\n",
        "  \n",
        "\n",
        "  # wordsSize, idio gia kathe dentro\n",
        "  wordsSize = random.randint(1000, len(words))\n",
        "\n",
        "  randomForest = []\n",
        "  resultRF = []\n",
        "\n",
        "  for i in range(numOfTrees):\n",
        "    sub_x = []\n",
        "    sub_y = []\n",
        "    for i in range(25000):\n",
        "      random_number = random.randint(0, 24999)\n",
        "      sub_x.append(x_train[random_number])\n",
        "      sub_y.append(y_train[random_number])\n",
        "\n",
        "    subWords = random.choices(words, k = wordsSize)\n",
        "    randomForest.append(ID3(sub_x, sub_y, subWords))\n",
        "\n",
        "  \n",
        "\n",
        "  for obj in randomForest:\n",
        "    temp = obj.run()\n",
        "    resultRF.append(temp)\n",
        "  \n",
        "  finalRF = predictRF(resultRF)\n",
        "\n",
        "  return finalRF\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdyPzH23qKd6"
      },
      "source": [
        "RF me etoimo id3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "tFjP5wFpe91D"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from random import randint\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "\n",
        "def tempRF(x_train, y_train, numOfTrees):\n",
        "\n",
        "  randomForest = []\n",
        "  \n",
        "  for i in range(numOfTrees):\n",
        "    \n",
        "    sub_x = []\n",
        "    sub_y = []\n",
        "    for i in range(len(x_train_binary)):\n",
        "      random_number = random.randint(0, len(x_train_binary) - 1)\n",
        "      sub_x.append(x_train[random_number])\n",
        "      sub_y.append(y_train[random_number])\n",
        "\n",
        "    dt = DecisionTreeClassifier(criterion='entropy')\n",
        "    dt.fit(sub_x, sub_y) # run() ton etoimo ID3\n",
        "    \n",
        "    temp = dt.predict(sub_x)\n",
        "    randomForest.append(temp) # @TODO (enna kamnw to idio prama, enna vallw mes ton randomForest[] ton pinaka pou enna epistrefei o apostolou)\n",
        "\n",
        "  \n",
        "  telikosPinakas = predictRF(randomForest)\n",
        "\n",
        "  return telikosPinakas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5Xo0Pv-8nfJ"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "print(classification_report(y_test, tempRF(x_test_binary, y_test, 25)))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "RF.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
